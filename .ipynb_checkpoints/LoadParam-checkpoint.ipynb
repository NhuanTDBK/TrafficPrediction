{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import pickle as pkl\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "# from sklearn import mean_squared_error\n",
    "from pandas import HDFStore\n",
    "store = HDFStore(\"storeTraffic.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input = 18\n",
    "def initNN(n_input):\n",
    "    #Build layer for MLP\n",
    "    l_in = ls.layers.InputLayer(shape=(None,n_input),input_var=None)\n",
    "    l_hidden = ls.layers.DenseLayer(l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "    network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "    print \"Neural network initialize\"\n",
    "    #Init Neural net\n",
    "    net1 = NeuralNet(\n",
    "        layers=network,\n",
    "        # optimization method:\n",
    "        update=nesterov_momentum,\n",
    "        update_learning_rate=0.000001,\n",
    "        update_momentum=0.9,\n",
    "        regression=True,  # flag to indicate we're dealing with regression problem\n",
    "        max_epochs=1000,  # we want to train this many epochs\n",
    "        verbose=1,\n",
    "    )\n",
    "    return net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network initialize\n",
      "Loaded parameters to layer 'dense1' (shape 18x15).\n",
      "Loaded parameters to layer 'dense1' (shape 15).\n",
      "Loaded parameters to layer 'dense2' (shape 15x1).\n",
      "Loaded parameters to layer 'dense2' (shape 1).\n",
      "Neural network initialize\n",
      "Loaded parameters to layer 'dense1' (shape 18x15).\n",
      "Loaded parameters to layer 'dense1' (shape 15).\n",
      "Loaded parameters to layer 'dense2' (shape 15x1).\n",
      "Loaded parameters to layer 'dense2' (shape 1).\n"
     ]
    }
   ],
   "source": [
    "net1 = initNN(n_input)\n",
    "net1.load_params_from('Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "net2 = initNN(n_input)\n",
    "net2.load_params_from('GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxC = store[\"raw_conn_train\"].max()\n",
    "minC = store[\"raw_conn_train\"].min()\n",
    "def convert(input):\n",
    "    return (input*(maxC-minC)+minC)\n",
    "def normalize(dataCount):\n",
    "    dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "    dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "    return dataNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "y_training loading...\n"
     ]
    }
   ],
   "source": [
    "data = store[\"connTrain\"]\n",
    "dataTest = store[\"raw_conn_test\"]\n",
    "n_row = data.shape[0]\n",
    "print \"Generate X_traing, y_traing\"\n",
    "print \"X_training loading...\"\n",
    "X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "             for t in np.arange(n_input,n_row)])\n",
    "print \"y_training loading...\"\n",
    "y_training = np.asarray(dataTest.iloc[n_input:n_row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_pred = convert(net1.predict(X_training))\n",
    "gn_pred = convert(net2.predict(X_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pl.subplot()\n",
    "ax.set_color_cycle(['blue','red','green'])\n",
    "# ax.plot(y_training,label=\"actual\")\n",
    "ax.plot(nn_pred,label=\"Simple Neural Network\")\n",
    "# ax.plot(gn_pred,label=\"Genetic Neural Network\")\n",
    "ax.plot(y_training,label=\"Actual\")\n",
    "ax.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
