{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import HDFStore\n",
    "import matplotlib.pyplot as pl\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from DemoPyEvolve import PyEvolve\n",
    "from ConfigParser import SafeConfigParser\n",
    "from __init__ import *\n",
    "store = HDFStore(\"storeTraffic.h5\")\n",
    "#\"ita_public_tools/output/data.csv\"\n",
    "data = pd.Series.from_csv(\"10min_workload.csv\",header=None,index_col=None)\n",
    "def read_config():\n",
    "    parser = SafeConfigParser()\n",
    "    parser.read('configNeural.cfg')\n",
    "    hidden_layer = int(parser.get(\"Neural\",\"hidden_layer\"))\n",
    "    epochs = int(parser.get(\"Neural\",\"epochs\"))\n",
    "    return hidden_layer, epochs\n",
    "def saveResult(nn_rmse,nn_map,nn_r2,gn_rmse,gn_map,gn_r2):\n",
    "    temp = np.zeros(6,dtype=np.float64)\n",
    "#     if(nn_rmse<=gn_rmse):\n",
    "#         temp[0]=gn_rmse\n",
    "#         temp[1]=gn_map\n",
    "#         temp[2]=gn_r2\n",
    "#         temp[3]=nn_rmse\n",
    "#         temp[4]=nn_map\n",
    "#         temp[5]=nn_r2\n",
    "#     else:\n",
    "    temp[0]=nn_rmse\n",
    "    temp[1]=nn_map\n",
    "    temp[2]=nn_r2\n",
    "    temp[3]=gn_rmse\n",
    "    temp[4]=gn_map\n",
    "    temp[5]=gn_r2\n",
    "    return temp\n",
    "def mean_percentage_error(y_pred,y_actual):\n",
    "    temp = [np.abs((i-j)/j) for i,j in zip(y_pred,y_actual)]\n",
    "    return np.sum(temp)\n",
    "class LoadParam():\n",
    "    def initNN(self):\n",
    "        #Build layer for MLP\n",
    "        hidden_layer, epochs = read_config()\n",
    "        l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None)\n",
    "        l_hidden = ls.layers.DenseLayer(l_in,num_units=hidden_layer,nonlinearity=ls.nonlinearities.rectify)\n",
    "        network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "#         print \"Neural network initialize\"\n",
    "        #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "            eval_size = 0.4\n",
    "#             verbose=1,\n",
    "        )\n",
    "        return net1\n",
    "    def initGN(self,params=None):\n",
    "        self.l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None,W=params.T)\n",
    "        self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "        self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "            #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=self.network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "#                 verbose=1,\n",
    "            eval_size = 0.4\n",
    "        )\n",
    "        return net1\n",
    "    def __init__(self,n_type,n_input,n_periodic=0):\n",
    "        self.n_input = n_input\n",
    "        self.n_periodic = n_periodic\n",
    "        self.n_type = n_type\n",
    "        if(n_periodic==0):\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('../Untitled Folder/Result9-1-2/Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('../Untitled Folder/Result9-1-2/GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('ParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "    def normalize(self,dataCount,dataTest):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataTest.min())/(dataTest.max()-dataTest.min())\n",
    "        return dataNorm\n",
    "    def normalize(self,dataCount):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "        return dataNorm\n",
    "    def convert(self,data):\n",
    "        max_val = float(self.workload.max())\n",
    "        min_val = float(self.workload.min())\n",
    "        return (data*(max_val-min_val)+min_val)\n",
    "    def generate(self,range_training,range_test=1):\n",
    "        # In[62]:\n",
    "#         print \"Loading storage\"\n",
    "#         print \"generate data\"\n",
    "        self.workload = data[142*range_training[0]-self.n_input:142*range_training[1]]\n",
    "        data_training = self.normalize(self.workload)\n",
    "        X_training = self.getTraining(self.workload)\n",
    "#         data_validation = data[142*range_training[1]-self.n_input:142*(range_training+range_test)]\n",
    "        data_test = data[142*range_training[0]:142*range_training[1]]\n",
    "        return np.asarray(X_training),np.asarray(data_test)\n",
    "    def getTraining(self,workload):\n",
    "        raw_data = data\n",
    "        data_training = self.normalize(workload)\n",
    "        max_val = float(workload.max())\n",
    "        min_val = float(workload.min())\n",
    "#         print max_val, min_val\n",
    "        n_row = data_training.shape[0]\n",
    "#         print \"Generate X_traing, y_traing\"\n",
    "#         print \"X_training loading...\"\n",
    "    #     X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "    #                  for t in np.arange(n_input,n_row)])\n",
    "        X_training = []\n",
    "        for t in range(self.n_input,n_row):\n",
    "            temp = []\n",
    "            for i in range(0,self.n_input):\n",
    "#                 print data_training.iloc[t-i-1]\n",
    "                temp.append(data_training.iloc[t-i-1])\n",
    "            for j in range(1,self.n_periodic+1):\n",
    "                start_idx = data_training.index[t]\n",
    "                norVal = (raw_data[start_idx-142*j]-min_val)/(max_val-min_val)\n",
    "#                 print raw_data[start_idx-142*j]\n",
    "                temp.append(norVal)\n",
    "            X_training.append(temp)\n",
    "        return X_training\n",
    "    def predict(self,X_test):\n",
    "#         dataTest= pd.read_sql(\"SELECT count FROM workload where time >= 895096802-%d and time < 895096802+86400\"%(n_input),conn)[\"count\"]\n",
    "        return self.net.predict(X_test)\n",
    "    def score(self,X_test,y_actual):\n",
    "        return self.net.score(X_test,y_actual)\n",
    "#     def plot_loss(self):\n",
    "#         \"\"\"\n",
    "#         Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "#         a trained neural network.\n",
    "#         \"\"\"\n",
    "#         net = self.net\n",
    "#         train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#         valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "#         pl.plot(train_loss, linewidth = 3, label = \"train\")\n",
    "#         pl.plot(valid_loss, linewidth = 3, label = \"valid\")\n",
    "#         pl.grid()\n",
    "#         pl.legend()\n",
    "#         pl.xlabel(\"epoch\")\n",
    "#         pl.ylabel(\"loss\")\n",
    "#         #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "#         pl.show()\n",
    "    def plot_loss(self,train_loss,valid_loss):\n",
    "        \"\"\"\n",
    "        Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "        a trained neural network.\n",
    "        \"\"\"\n",
    "        pl.plot(train_loss, linewidth = 2, label = \"train\")\n",
    "        pl.plot(valid_loss, linewidth = 2, label = \"valid\")\n",
    "\n",
    "        pl.legend()\n",
    "        pl.xlabel(\"epoch\")\n",
    "        pl.ylabel(\"loss\")\n",
    "        #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "        pl.show()\n",
    "    def fitTraining(self,X_training,y_training):\n",
    "        if(self.n_type==\"GN\"):\n",
    "            geneticEngine = PyEvolve(n_input)\n",
    "            geneticEngine.fit()\n",
    "            nnParams = geneticEngine.getParam()\n",
    "            self.net = self.initGN(nnParams)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "        self.net.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pl.subplot()\n",
    "# ax.set_color_cycle(['red','blue','green'])\n",
    "# ax.plot(result_score[\"MAPE_NN\"],label=\"MAPE NN\")\n",
    "# ax.set_xlim(xmin=2)\n",
    "# ax.plot(result_score[\"MAPE_GN\"],label=\"MAPE GN\")\n",
    "# # ax.plot(nn_pred,label=\"Neural Network\")\n",
    "# ax.plot()\n",
    "# ax.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# ax1 = result_score[\"MAE_GN\"].plot(kind='line',title=\"MAE vs. Window size (Neural Network)\",grid=False)\n",
    "# ax1.set_ylabel(\"Mean absolute error (MAE)\")\n",
    "# ax1.set_xlabel(\"Sliding Window size\")\n",
    "# ax1.set_color_cycle(['red'])\n",
    "# result_score[\"MAE_NN\"].plot(kind='line',label=\"MAE NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_nresult = []\n",
    "for n_input in np.arange(2,21):\n",
    "    temp = np.zeros(6)\n",
    "    temp=[]\n",
    "#     n_input = 12\n",
    "    nn = LoadParam(\"GN\",n_input)\n",
    "    gn = LoadParam(\"GN\",n_input,1)\n",
    "    #     print \"With input\"\n",
    "    #     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "    i = 7\n",
    "    skip_list = 3\n",
    "    #     print \"%d-%d\"%(i,i+skip_list)\n",
    "    # X_training,y_training = nn.generate((i,i+skip_list))\n",
    "    X_test,y_test = nn.generate((i,i+skip_list))\n",
    "    X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "        # Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "        # Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "        # nn.fitTraining(X_training,y_training)\n",
    "        # nnp.fitTraining(Xp_training,yp_training)\n",
    "        # dataX = data[142*3:142*5]\n",
    "    #     print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "    #     print \"GN score = %f\"%gn.score(X_ptest,y_ptest)\n",
    "    #     temp.append(nn.score(nn.convert(X_test),nn.convert(y_test)))\n",
    "    nn_pred = nn.convert(nn.predict(X_test))\n",
    "    gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    \n",
    "    temp.append(np.sqrt(mean_squared_error(nn_pred,y_test)))\n",
    "    temp.append(mean_absolute_error(nn_pred,y_test))\n",
    "    temp.append(r2_score(y_test,nn_pred))\n",
    "    temp.append(mean_percentage_error(y_test,nn_pred))\n",
    "    \n",
    "    temp.append(np.sqrt(mean_squared_error(gn_pred,y_ptest)))\n",
    "    temp.append(mean_absolute_error(gn_pred,y_ptest))\n",
    "    temp.append(r2_score(y_ptest,gn_pred))\n",
    "    temp.append(mean_percentage_error(y_ptest,gn_pred))\n",
    "    \n",
    "    list_nresult.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network initialize\n",
      "Neural network initialize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/nolearn/lasagne/base.py:206: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "# n_input = 4\n",
    "# nn = LoadParam(\"GN\",4)\n",
    "# gn = LoadParam(\"GN\",n_input,1)\n",
    "# i = 46\n",
    "# skip_list = 2\n",
    "# X_test,y_test = nn.generate((i,i+skip_list))\n",
    "# X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "\n",
    "# gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "# nn_pred = nn.convert(nn.predict(X_test))\n",
    "# y_actual = y_test\n",
    "# ax2 = pl.subplot()\n",
    "# ax2.set_color_cycle(['blue','red','green'])\n",
    "# ax2.plot(nn_pred,'--',label=\"Not Periodic\")\n",
    "# ax2.plot(gn_pred,'--',label=\"Periodic\")\n",
    "# ax2.plot(y_actual,label=\"Actual\")\n",
    "# ax2.set_title(\"Genetic Neural Network with Periodic based Prediction (Sliding Window Size = 4)\")\n",
    "# ax2.set_ylabel(\"Connections\")\n",
    "# ax2.set_xlabel(\"Time (minutes)\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "# ax2.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_NN</th>\n",
       "      <th>MAE_NN</th>\n",
       "      <th>R2_NN</th>\n",
       "      <th>MAPE_NN</th>\n",
       "      <th>RMSE_GN</th>\n",
       "      <th>MAE_GN</th>\n",
       "      <th>R2_GN</th>\n",
       "      <th>MAPE_GN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td>  980.436910</td>\n",
       "      <td>  738.049179</td>\n",
       "      <td> 0.918072</td>\n",
       "      <td>  39.058482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> 1640.957090</td>\n",
       "      <td> 1360.837171</td>\n",
       "      <td> 0.770498</td>\n",
       "      <td>  68.521956</td>\n",
       "      <td>  966.398453</td>\n",
       "      <td>  725.553674</td>\n",
       "      <td> 0.920402</td>\n",
       "      <td>  38.563987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td> 1084.589336</td>\n",
       "      <td>  807.462781</td>\n",
       "      <td> 0.899741</td>\n",
       "      <td>  43.234061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 2063.511088</td>\n",
       "      <td> 1598.792058</td>\n",
       "      <td> 0.637085</td>\n",
       "      <td>  81.532308</td>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 5723.896835</td>\n",
       "      <td> 4585.838123</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.306762</td>\n",
       "      <td> 1021.943970</td>\n",
       "      <td>  765.487381</td>\n",
       "      <td> 0.910989</td>\n",
       "      <td>  40.656354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 1827.496725</td>\n",
       "      <td> 1508.047254</td>\n",
       "      <td> 0.715354</td>\n",
       "      <td>  75.725333</td>\n",
       "      <td> 1029.879430</td>\n",
       "      <td>  774.167824</td>\n",
       "      <td> 0.909601</td>\n",
       "      <td>  42.008215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 5483.078418</td>\n",
       "      <td> 4207.458643</td>\n",
       "      <td>-1.562363</td>\n",
       "      <td> 453.581184</td>\n",
       "      <td> 1049.716179</td>\n",
       "      <td>  787.150886</td>\n",
       "      <td> 0.906085</td>\n",
       "      <td>  42.183648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td> 1148.050925</td>\n",
       "      <td>  859.010174</td>\n",
       "      <td> 0.887665</td>\n",
       "      <td>  44.693136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td> 1104.845187</td>\n",
       "      <td>  842.160497</td>\n",
       "      <td> 0.895961</td>\n",
       "      <td>  44.987338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 1217.715182</td>\n",
       "      <td>  909.905513</td>\n",
       "      <td> 0.873619</td>\n",
       "      <td>  47.438278</td>\n",
       "      <td> 1152.968287</td>\n",
       "      <td>  867.874411</td>\n",
       "      <td> 0.886701</td>\n",
       "      <td>  46.174697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 1612.876679</td>\n",
       "      <td> 1228.250902</td>\n",
       "      <td> 0.778286</td>\n",
       "      <td>  60.617777</td>\n",
       "      <td> 1091.537013</td>\n",
       "      <td>  828.069815</td>\n",
       "      <td> 0.898453</td>\n",
       "      <td>  44.240521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 1370.637679</td>\n",
       "      <td> 1126.738434</td>\n",
       "      <td> 0.839883</td>\n",
       "      <td>  57.481843</td>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 2033.885068</td>\n",
       "      <td> 1565.643798</td>\n",
       "      <td> 0.647431</td>\n",
       "      <td>  87.519708</td>\n",
       "      <td> 1124.358310</td>\n",
       "      <td>  845.994182</td>\n",
       "      <td> 0.892254</td>\n",
       "      <td>  44.913617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 5569.193072</td>\n",
       "      <td> 4376.291756</td>\n",
       "      <td>-1.643482</td>\n",
       "      <td> 482.612523</td>\n",
       "      <td> 1143.729652</td>\n",
       "      <td>  866.287928</td>\n",
       "      <td> 0.888509</td>\n",
       "      <td>  46.210089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td> 1129.620129</td>\n",
       "      <td>  871.557317</td>\n",
       "      <td> 0.891243</td>\n",
       "      <td>  46.327211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td> 1840.935950</td>\n",
       "      <td> 1470.550031</td>\n",
       "      <td> 0.711152</td>\n",
       "      <td>  72.400019</td>\n",
       "      <td> 1081.409125</td>\n",
       "      <td>  817.163033</td>\n",
       "      <td> 0.900328</td>\n",
       "      <td>  42.931053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "      <td> 1156.607857</td>\n",
       "      <td>  883.576403</td>\n",
       "      <td> 0.885984</td>\n",
       "      <td>  46.625296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td> 5721.929199</td>\n",
       "      <td> 4581.261914</td>\n",
       "      <td>-1.790466</td>\n",
       "      <td> 523.478464</td>\n",
       "      <td> 5723.896909</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td> 524.308105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td> 1858.592884</td>\n",
       "      <td> 1391.500469</td>\n",
       "      <td> 0.705585</td>\n",
       "      <td>  71.831119</td>\n",
       "      <td> 1330.872728</td>\n",
       "      <td> 1002.291679</td>\n",
       "      <td> 0.849039</td>\n",
       "      <td>  52.297446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE_NN       MAE_NN     R2_NN     MAPE_NN      RMSE_GN       MAE_GN  \\\n",
       "2   5723.896909  4585.849765 -1.792385  524.308105   980.436910   738.049179   \n",
       "3   1640.957090  1360.837171  0.770498   68.521956   966.398453   725.553674   \n",
       "4   5723.896909  4585.849765 -1.792385  524.308105  1084.589336   807.462781   \n",
       "5   2063.511088  1598.792058  0.637085   81.532308  5723.896909  4585.849765   \n",
       "6   5723.896835  4585.838123 -1.792385  524.306762  1021.943970   765.487381   \n",
       "7   1827.496725  1508.047254  0.715354   75.725333  1029.879430   774.167824   \n",
       "8   5483.078418  4207.458643 -1.562363  453.581184  1049.716179   787.150886   \n",
       "9   5723.896909  4585.849765 -1.792385  524.308105  1148.050925   859.010174   \n",
       "10  5723.896909  4585.849765 -1.792385  524.308105  1104.845187   842.160497   \n",
       "11  1217.715182   909.905513  0.873619   47.438278  1152.968287   867.874411   \n",
       "12  1612.876679  1228.250902  0.778286   60.617777  1091.537013   828.069815   \n",
       "13  1370.637679  1126.738434  0.839883   57.481843  5723.896909  4585.849765   \n",
       "14  2033.885068  1565.643798  0.647431   87.519708  1124.358310   845.994182   \n",
       "15  5569.193072  4376.291756 -1.643482  482.612523  1143.729652   866.287928   \n",
       "16  5723.896909  4585.849765 -1.792385  524.308105  1129.620129   871.557317   \n",
       "17  1840.935950  1470.550031  0.711152   72.400019  1081.409125   817.163033   \n",
       "18  5723.896909  4585.849765 -1.792385  524.308105  1156.607857   883.576403   \n",
       "19  5721.929199  4581.261914 -1.790466  523.478464  5723.896909  4585.849765   \n",
       "20  1858.592884  1391.500469  0.705585   71.831119  1330.872728  1002.291679   \n",
       "\n",
       "       R2_GN     MAPE_GN  \n",
       "2   0.918072   39.058482  \n",
       "3   0.920402   38.563987  \n",
       "4   0.899741   43.234061  \n",
       "5  -1.792385  524.308105  \n",
       "6   0.910989   40.656354  \n",
       "7   0.909601   42.008215  \n",
       "8   0.906085   42.183648  \n",
       "9   0.887665   44.693136  \n",
       "10  0.895961   44.987338  \n",
       "11  0.886701   46.174697  \n",
       "12  0.898453   44.240521  \n",
       "13 -1.792385  524.308105  \n",
       "14  0.892254   44.913617  \n",
       "15  0.888509   46.210089  \n",
       "16  0.891243   46.327211  \n",
       "17  0.900328   42.931053  \n",
       "18  0.885984   46.625296  \n",
       "19 -1.792385  524.308105  \n",
       "20  0.849039   52.297446  \n",
       "\n",
       "[19 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nresult= pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"MAPE_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\",\"MAPE_GN\"],index=np.arange(2,21))\n",
    "list_nresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7f4ae01a4790>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "list_nresult[\"MAPE_GN\"].plot(kind=\"line\")\n",
    "list_nresult[\"MAPE_NN\"].plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_GNP</th>\n",
       "      <th>MAE_GNP</th>\n",
       "      <th>R2_GNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4497.238768</td>\n",
       "      <td>-1.754937e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 80803970.560424</td>\n",
       "      <td> 4562.884071</td>\n",
       "      <td>-2.979586e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.339129e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td> 0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 14011011.800485</td>\n",
       "      <td> 4453.220734</td>\n",
       "      <td>-1.665042e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-5.356515e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 80819424.451805</td>\n",
       "      <td> 4368.549213</td>\n",
       "      <td>-4.008825e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4584.944753</td>\n",
       "      <td>-1.499707e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 80713595.004481</td>\n",
       "      <td> 4533.282767</td>\n",
       "      <td>-5.922975e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 46584759.136363</td>\n",
       "      <td> 4276.780719</td>\n",
       "      <td>-8.535948e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4578.297616</td>\n",
       "      <td>-7.121162e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-6.722319e+31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RMSE_GNP      MAE_GNP        R2_GNP\n",
       "4   80819824.276995  4497.238768 -1.754937e+03\n",
       "5   80803970.560424  4562.884071 -2.979586e+03\n",
       "6   80819824.276995  4585.849765 -1.339129e+32\n",
       "7   80819824.276995  4585.849765  0.000000e+00\n",
       "8   14011011.800485  4453.220734 -1.665042e+02\n",
       "9   80819824.276995  4585.849765 -5.356515e+32\n",
       "10  80819424.451805  4368.549213 -4.008825e+02\n",
       "11  80819824.276995  4584.944753 -1.499707e+05\n",
       "12  80713595.004481  4533.282767 -5.922975e+02\n",
       "13  46584759.136363  4276.780719 -8.535948e+01\n",
       "14  80819824.276995  4578.297616 -7.121162e+03\n",
       "15  80819824.276995  4585.849765 -6.722319e+31\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_GNP\",\"MAE_GNP\",\"R2_GNP\"],index=np.arange(4,16))\n",
    "result_score\n",
    "# temp = result_score[\"MAE_GN\"][13]\n",
    "# result_score[\"MAE_GN\"][13]=result_score[\"MAE_GN\"][11]\n",
    "# result_score[\"MAE_GN\"][11]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4ae015bcd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "ax1 = list_nresult[\"MAPE_GN\"].plot(kind='line',color='red',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax2 = list_nresult[\"MAPE_NN\"].plot(kind='line',color='blue',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax1.set_xlabel(\"Sliding Window size\")\n",
    "ax1.set_ylabel(\"Mean Absolute Error (MAE)\")\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67259.816459331167"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_percentage_error(gn_pred,y_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = np.abs((gn_pred-y_ptest)/y_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.04330678]),\n",
       " array([ 0.02635537]),\n",
       " array([ 0.06849578]),\n",
       " array([ 0.04810875]),\n",
       " array([ 0.10598131]),\n",
       " array([ 0.1060608]),\n",
       " array([ 0.24671065]),\n",
       " array([ 0.23063355]),\n",
       " array([ 0.13027466]),\n",
       " array([ 0.07426701]),\n",
       " array([ 0.17447558]),\n",
       " array([ 0.08575113]),\n",
       " array([ 0.0546869]),\n",
       " array([ 0.07669562]),\n",
       " array([ 0.14296931]),\n",
       " array([ 0.10232259]),\n",
       " array([ 0.16006103]),\n",
       " array([ 0.17277846]),\n",
       " array([ 0.12486561]),\n",
       " array([ 0.38240901]),\n",
       " array([ 0.17678269]),\n",
       " array([ 0.12484352]),\n",
       " array([ 0.01568442]),\n",
       " array([ 0.12315331]),\n",
       " array([ 0.11927366]),\n",
       " array([ 0.14277813]),\n",
       " array([ 0.09137446]),\n",
       " array([ 0.05566349]),\n",
       " array([ 0.10243393]),\n",
       " array([ 0.11550993]),\n",
       " array([ 0.00119718]),\n",
       " array([ 0.05977133]),\n",
       " array([ 0.06539166]),\n",
       " array([ 0.09415017]),\n",
       " array([ 0.04841261]),\n",
       " array([ 0.16073003]),\n",
       " array([ 0.00697213]),\n",
       " array([ 0.15499523]),\n",
       " array([ 0.00359752]),\n",
       " array([ 0.05644425]),\n",
       " array([ 0.06765217]),\n",
       " array([ 0.03805465]),\n",
       " array([ 0.03727227]),\n",
       " array([ 0.07027797]),\n",
       " array([ 0.11910814]),\n",
       " array([ 0.18316411]),\n",
       " array([ 0.20892603]),\n",
       " array([ 0.09151183]),\n",
       " array([ 0.06947249]),\n",
       " array([ 0.07510475]),\n",
       " array([ 0.10718074]),\n",
       " array([ 0.02244737]),\n",
       " array([ 0.09711569]),\n",
       " array([ 0.16107224]),\n",
       " array([ 0.07393634]),\n",
       " array([ 0.04702947]),\n",
       " array([ 0.14223869]),\n",
       " array([ 0.1256023]),\n",
       " array([ 0.33721743]),\n",
       " array([ 0.03509349]),\n",
       " array([ 0.01068941]),\n",
       " array([ 0.03847067]),\n",
       " array([ 0.00643437]),\n",
       " array([ 0.0942007]),\n",
       " array([ 0.03220705]),\n",
       " array([ 0.01229807]),\n",
       " array([ 0.0765057]),\n",
       " array([ 0.034179]),\n",
       " array([ 0.0455972]),\n",
       " array([ 0.05902198]),\n",
       " array([ 0.02664261]),\n",
       " array([ 0.01112173]),\n",
       " array([ 0.00585449]),\n",
       " array([ 0.01077325]),\n",
       " array([ 0.00285687]),\n",
       " array([ 0.03139721]),\n",
       " array([ 0.04533209]),\n",
       " array([ 0.01889205]),\n",
       " array([ 0.03178281]),\n",
       " array([ 0.03165636]),\n",
       " array([ 0.00643699]),\n",
       " array([ 0.02195253]),\n",
       " array([ 0.00444987]),\n",
       " array([ 0.02148547]),\n",
       " array([ 0.04987741]),\n",
       " array([ 0.03438311]),\n",
       " array([ 0.06529311]),\n",
       " array([ 0.05613455]),\n",
       " array([ 0.02615407]),\n",
       " array([ 0.0100593]),\n",
       " array([ 0.09056908]),\n",
       " array([ 0.01835943]),\n",
       " array([ 0.00345]),\n",
       " array([ 0.01247678]),\n",
       " array([ 0.03091568]),\n",
       " array([ 0.05951079]),\n",
       " array([ 0.03877069]),\n",
       " array([ 0.04086025]),\n",
       " array([ 0.03476004]),\n",
       " array([ 0.10282555]),\n",
       " array([ 0.0815621]),\n",
       " array([ 0.05981732]),\n",
       " array([ 0.1019763]),\n",
       " array([ 0.07363995]),\n",
       " array([ 0.0887494]),\n",
       " array([ 0.04234831]),\n",
       " array([ 0.04396483]),\n",
       " array([ 0.10609508]),\n",
       " array([ 0.00365927]),\n",
       " array([ 0.01150377]),\n",
       " array([ 0.06083606]),\n",
       " array([ 0.02257456]),\n",
       " array([ 0.06089563]),\n",
       " array([ 0.03947647]),\n",
       " array([ 0.00357987]),\n",
       " array([ 0.08965553]),\n",
       " array([ 0.00720398]),\n",
       " array([ 0.02003023]),\n",
       " array([ 0.06548673]),\n",
       " array([ 0.01747629]),\n",
       " array([ 0.05590304]),\n",
       " array([ 0.04058205]),\n",
       " array([ 0.04086748]),\n",
       " array([ 0.02578219]),\n",
       " array([ 0.06694369]),\n",
       " array([ 0.03760512]),\n",
       " array([ 0.02545176]),\n",
       " array([ 0.04204727]),\n",
       " array([ 0.03079002]),\n",
       " array([ 0.02877488]),\n",
       " array([ 0.06088919]),\n",
       " array([ 0.00421264]),\n",
       " array([ 0.06752506]),\n",
       " array([ 0.00182043]),\n",
       " array([ 0.0466669]),\n",
       " array([ 0.06468129]),\n",
       " array([ 0.02800712]),\n",
       " array([ 0.03869529]),\n",
       " array([ 0.09311964]),\n",
       " array([ 0.05612424]),\n",
       " array([ 0.07576245]),\n",
       " array([ 0.04602552]),\n",
       " array([ 0.09889884]),\n",
       " array([ 0.07793853]),\n",
       " array([ 0.01451622]),\n",
       " array([ 0.06408464]),\n",
       " array([ 0.10143373]),\n",
       " array([ 0.00576856]),\n",
       " array([ 0.07594099]),\n",
       " array([ 0.08823627]),\n",
       " array([ 0.01258212]),\n",
       " array([ 0.03099771]),\n",
       " array([ 0.0199698]),\n",
       " array([ 0.05116749]),\n",
       " array([ 0.01464591]),\n",
       " array([ 0.01149199]),\n",
       " array([ 0.11123162]),\n",
       " array([ 0.00274123]),\n",
       " array([ 0.09743307]),\n",
       " array([ 0.15368525]),\n",
       " array([ 0.14953426]),\n",
       " array([ 0.00923302]),\n",
       " array([ 0.07085717]),\n",
       " array([ 0.02133961]),\n",
       " array([ 0.00313838]),\n",
       " array([ 0.07163916]),\n",
       " array([ 0.02008475]),\n",
       " array([ 0.015358]),\n",
       " array([ 0.1788174]),\n",
       " array([ 0.17809804]),\n",
       " array([ 0.01506603]),\n",
       " array([ 0.01989857]),\n",
       " array([ 0.00922763]),\n",
       " array([ 0.0405654]),\n",
       " array([ 0.07533149]),\n",
       " array([ 0.03674568]),\n",
       " array([ 0.04815895]),\n",
       " array([ 0.04507688]),\n",
       " array([ 0.02200393]),\n",
       " array([ 0.10429272]),\n",
       " array([ 0.35984689]),\n",
       " array([ 0.08206785]),\n",
       " array([ 0.01876128]),\n",
       " array([ 0.00485445]),\n",
       " array([ 0.11568086]),\n",
       " array([ 0.01688441]),\n",
       " array([ 0.05583461]),\n",
       " array([ 0.12264176]),\n",
       " array([ 0.0381642]),\n",
       " array([ 0.06631748]),\n",
       " array([ 0.07508218]),\n",
       " array([ 0.04307684]),\n",
       " array([ 0.03007485]),\n",
       " array([ 0.00510233]),\n",
       " array([ 0.05797904]),\n",
       " array([ 0.1671408]),\n",
       " array([ 0.00464277]),\n",
       " array([ 0.03428766]),\n",
       " array([ 0.07999864]),\n",
       " array([ 0.07645953]),\n",
       " array([ 0.10025194]),\n",
       " array([ 0.10301066]),\n",
       " array([ 0.21602362]),\n",
       " array([ 0.10293739]),\n",
       " array([ 0.04079765]),\n",
       " array([ 0.00051749]),\n",
       " array([ 0.10533796]),\n",
       " array([ 0.06112031]),\n",
       " array([ 0.06306933]),\n",
       " array([ 0.07488146]),\n",
       " array([ 0.03579764]),\n",
       " array([ 0.06293602]),\n",
       " array([ 0.02332933]),\n",
       " array([ 0.0426803]),\n",
       " array([ 0.02614322]),\n",
       " array([ 0.05260096]),\n",
       " array([ 0.04281579]),\n",
       " array([ 0.01930138]),\n",
       " array([ 0.11968147]),\n",
       " array([ 0.02732704]),\n",
       " array([ 0.05343949]),\n",
       " array([ 0.02859378]),\n",
       " array([ 0.06899967]),\n",
       " array([ 0.03457236]),\n",
       " array([ 0.03929191]),\n",
       " array([ 0.01395161]),\n",
       " array([ 0.01643339]),\n",
       " array([ 0.01597494]),\n",
       " array([ 0.07318221]),\n",
       " array([ 0.02843891]),\n",
       " array([ 0.08603116]),\n",
       " array([ 0.01240052]),\n",
       " array([ 0.07421846]),\n",
       " array([ 0.01248089]),\n",
       " array([ 0.081104]),\n",
       " array([ 0.02032383]),\n",
       " array([ 0.11172738]),\n",
       " array([ 0.02409209]),\n",
       " array([ 0.00404304]),\n",
       " array([ 0.02958295]),\n",
       " array([ 0.01413993]),\n",
       " array([ 0.05151254]),\n",
       " array([ 0.06402331]),\n",
       " array([ 0.0656436]),\n",
       " array([ 0.11595192]),\n",
       " array([ 0.10537055]),\n",
       " array([ 0.09386566]),\n",
       " array([ 0.11512736]),\n",
       " array([ 0.08940272]),\n",
       " array([ 0.12949309]),\n",
       " array([ 0.04322467]),\n",
       " array([ 0.14138222]),\n",
       " array([ 0.00986081]),\n",
       " array([ 0.08572434]),\n",
       " array([ 0.02625165]),\n",
       " array([ 0.00328408]),\n",
       " array([ 0.00056345]),\n",
       " array([ 0.01977563]),\n",
       " array([ 0.03146775]),\n",
       " array([ 0.03663624]),\n",
       " array([ 0.0128437]),\n",
       " array([  1.57209380e-05]),\n",
       " array([ 0.00709754]),\n",
       " array([ 0.02465362]),\n",
       " array([ 0.02433517]),\n",
       " array([ 0.00597114]),\n",
       " array([ 0.03954269]),\n",
       " array([ 0.03047358]),\n",
       " array([ 0.03623961]),\n",
       " array([ 0.00329449]),\n",
       " array([ 0.01151506]),\n",
       " array([ 0.02948286]),\n",
       " array([ 0.03075008]),\n",
       " array([ 0.02559429]),\n",
       " array([ 0.01842717]),\n",
       " array([ 0.02172765]),\n",
       " array([ 0.00192781]),\n",
       " array([ 0.01245665]),\n",
       " array([ 0.01451783]),\n",
       " array([ 0.00855006]),\n",
       " array([ 0.00133094]),\n",
       " array([ 0.028898]),\n",
       " array([ 0.02673952]),\n",
       " array([ 0.00868433])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.abs((i-j)/j) for i,j in zip(gn_pred,y_ptest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
