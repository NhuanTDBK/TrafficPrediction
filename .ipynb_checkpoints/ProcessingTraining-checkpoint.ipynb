{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import HDFStore\n",
    "import matplotlib.pyplot as pl\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from DemoPyEvolve import PyEvolve\n",
    "from ConfigParser import SafeConfigParser\n",
    "from __init__ import *\n",
    "store = HDFStore(\"storeTraffic.h5\")\n",
    "#\"ita_public_tools/output/data.csv\"\n",
    "data = pd.Series.from_csv(\"10min_workload.csv\",header=None,index_col=None)\n",
    "def read_config():\n",
    "    parser = SafeConfigParser()\n",
    "    parser.read('configNeural.cfg')\n",
    "    hidden_layer = int(parser.get(\"Neural\",\"hidden_layer\"))\n",
    "    epochs = int(parser.get(\"Neural\",\"epochs\"))\n",
    "    return hidden_layer, epochs\n",
    "def saveResult(nn_rmse,nn_map,nn_r2,gn_rmse,gn_map,gn_r2):\n",
    "    temp = np.zeros(6,dtype=np.float64)\n",
    "#     if(nn_rmse<=gn_rmse):\n",
    "#         temp[0]=gn_rmse\n",
    "#         temp[1]=gn_map\n",
    "#         temp[2]=gn_r2\n",
    "#         temp[3]=nn_rmse\n",
    "#         temp[4]=nn_map\n",
    "#         temp[5]=nn_r2\n",
    "#     else:\n",
    "    temp[0]=nn_rmse\n",
    "    temp[1]=nn_map\n",
    "    temp[2]=nn_r2\n",
    "    temp[3]=gn_rmse\n",
    "    temp[4]=gn_map\n",
    "    temp[5]=gn_r2\n",
    "    return temp\n",
    "class LoadParam():\n",
    "    def initNN(self):\n",
    "        #Build layer for MLP\n",
    "        hidden_layer, epochs = read_config()\n",
    "        l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None)\n",
    "        l_hidden = ls.layers.DenseLayer(l_in,num_units=hidden_layer,nonlinearity=ls.nonlinearities.rectify)\n",
    "        network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "        print \"Neural network initialize\"\n",
    "        #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "            eval_size = 0.4\n",
    "#             verbose=1,\n",
    "        )\n",
    "        return net1\n",
    "    def initGN(self,params=None):\n",
    "        self.l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None,W=params.T)\n",
    "        self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "        self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "            #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=self.network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "#                 verbose=1,\n",
    "            eval_size = 0.4\n",
    "        )\n",
    "        return net1\n",
    "    def __init__(self,n_type,n_input,n_periodic=0):\n",
    "        self.n_input = n_input\n",
    "        self.n_periodic = n_periodic\n",
    "        self.n_type = n_type\n",
    "        if(n_periodic==0):\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('ParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "    def normalize(self,dataCount,dataTest):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataTest.min())/(dataTest.max()-dataTest.min())\n",
    "        return dataNorm\n",
    "    def normalize(self,dataCount):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "        return dataNorm\n",
    "    def convert(self,data):\n",
    "        max_val = float(self.workload.max())\n",
    "        min_val = float(self.workload.min())\n",
    "        return (data*(max_val-min_val)+min_val)\n",
    "    def generate(self,range_training,range_test=1):\n",
    "        # In[62]:\n",
    "        print \"Loading storage\"\n",
    "        print \"generate data\"\n",
    "        self.workload = data[142*range_training[0]-self.n_input:142*range_training[1]]\n",
    "        data_training = self.normalize(self.workload)\n",
    "        X_training = self.getTraining(self.workload)\n",
    "#         data_validation = data[142*range_training[1]-self.n_input:142*(range_training+range_test)]\n",
    "        data_test = data[142*range_training[0]:142*range_training[1]]\n",
    "        return np.asarray(X_training),np.asarray(data_test)\n",
    "    def getTraining(self,workload):\n",
    "        raw_data = data\n",
    "        data_training = self.normalize(workload)\n",
    "        max_val = float(workload.max())\n",
    "        min_val = float(workload.min())\n",
    "        print max_val, min_val\n",
    "        n_row = data_training.shape[0]\n",
    "        print \"Generate X_traing, y_traing\"\n",
    "        print \"X_training loading...\"\n",
    "    #     X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "    #                  for t in np.arange(n_input,n_row)])\n",
    "        X_training = []\n",
    "        for t in range(self.n_input,n_row):\n",
    "            temp = []\n",
    "            for i in range(0,self.n_input):\n",
    "#                 print data_training.iloc[t-i-1]\n",
    "                temp.append(data_training.iloc[t-i-1])\n",
    "            for j in range(1,self.n_periodic+1):\n",
    "                start_idx = data_training.index[t]\n",
    "                norVal = (raw_data[start_idx-142*j]-min_val)/(max_val-min_val)\n",
    "                print raw_data[start_idx-142*j]\n",
    "                temp.append(norVal)\n",
    "            X_training.append(temp)\n",
    "        return X_training\n",
    "    def predict(self,X_test):\n",
    "#         dataTest= pd.read_sql(\"SELECT count FROM workload where time >= 895096802-%d and time < 895096802+86400\"%(n_input),conn)[\"count\"]\n",
    "        return self.net.predict(X_test)\n",
    "    def score(self,X_test,y_actual):\n",
    "        return self.net.score(X_test,y_actual)\n",
    "#     def plot_loss(self):\n",
    "#         \"\"\"\n",
    "#         Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "#         a trained neural network.\n",
    "#         \"\"\"\n",
    "#         net = self.net\n",
    "#         train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#         valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "#         pl.plot(train_loss, linewidth = 3, label = \"train\")\n",
    "#         pl.plot(valid_loss, linewidth = 3, label = \"valid\")\n",
    "#         pl.grid()\n",
    "#         pl.legend()\n",
    "#         pl.xlabel(\"epoch\")\n",
    "#         pl.ylabel(\"loss\")\n",
    "#         #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "#         pl.show()\n",
    "    def plot_loss(self,train_loss,valid_loss):\n",
    "        \"\"\"\n",
    "        Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "        a trained neural network.\n",
    "        \"\"\"\n",
    "        pl.plot(train_loss, linewidth = 2, label = \"train\")\n",
    "        pl.plot(valid_loss, linewidth = 2, label = \"valid\")\n",
    "\n",
    "        pl.legend()\n",
    "        pl.xlabel(\"epoch\")\n",
    "        pl.ylabel(\"loss\")\n",
    "        #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "        pl.show()\n",
    "    def fitTraining(self,X_training,y_training):\n",
    "        if(self.n_type==\"GN\"):\n",
    "            geneticEngine = PyEvolve(n_input)\n",
    "            geneticEngine.fit()\n",
    "            nnParams = geneticEngine.getParam()\n",
    "            self.net = self.initGN(nnParams)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "        self.net.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Loading storage\n",
      "generate data\n",
      "17515 3726\n",
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "Loading storage\n",
      "generate data\n",
      "17515 3726\n",
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "14885\n",
      "12328\n",
      "10893\n",
      "10657\n",
      "11669\n",
      "10784\n",
      "11235\n",
      "11184\n",
      "10420\n",
      "9305\n",
      "8593\n",
      "9093\n",
      "7560\n",
      "8073\n",
      "9224\n",
      "7730\n",
      "9601\n",
      "8933\n",
      "9396\n",
      "8362\n",
      "9006\n",
      "8918\n",
      "7582\n",
      "9146\n",
      "8683\n",
      "7531\n",
      "8133\n",
      "8442\n",
      "7566\n",
      "8945\n",
      "7754\n",
      "6935\n",
      "8385\n",
      "9332\n",
      "9940\n",
      "7400\n",
      "6222\n",
      "6867\n",
      "8730\n",
      "6937\n",
      "6345\n",
      "8739\n",
      "9823\n",
      "6598\n",
      "5568\n",
      "5394\n",
      "4798\n",
      "5333\n",
      "6894\n",
      "8101\n",
      "6388\n",
      "5949\n",
      "5719\n",
      "7837\n",
      "6007\n",
      "6302\n",
      "6802\n",
      "7213\n",
      "8271\n",
      "10751\n",
      "9648\n",
      "11174\n",
      "8917\n",
      "11238\n",
      "11058\n",
      "9569\n",
      "10732\n",
      "11194\n",
      "11587\n",
      "11810\n",
      "11919\n",
      "14142\n",
      "12354\n",
      "10630\n",
      "12865\n",
      "13270\n",
      "11590\n",
      "14411\n",
      "12401\n",
      "13422\n",
      "15563\n",
      "11985\n",
      "12193\n",
      "13544\n",
      "14231\n",
      "14923\n",
      "15263\n",
      "12567\n",
      "11338\n",
      "12321\n",
      "13554\n",
      "14386\n",
      "15288\n",
      "16342\n",
      "14807\n",
      "15250\n",
      "16807\n",
      "17229\n",
      "15451\n",
      "15644\n",
      "19373\n",
      "19818\n",
      "17398\n",
      "16392\n",
      "16916\n",
      "19521\n",
      "16927\n",
      "16856\n",
      "17666\n",
      "18522\n",
      "17536\n",
      "14780\n",
      "15859\n",
      "17959\n",
      "17761\n",
      "13457\n",
      "17261\n",
      "17917\n",
      "17328\n",
      "16544\n",
      "16707\n",
      "16792\n",
      "18111\n",
      "16770\n",
      "17065\n",
      "17531\n",
      "14427\n",
      "13431\n",
      "13576\n",
      "13232\n",
      "13667\n",
      "14154\n",
      "11747\n",
      "14568\n",
      "11944\n",
      "11498\n",
      "7592\n",
      "11576\n",
      "12059\n",
      "11899\n",
      "14524\n",
      "12687\n",
      "13846\n",
      "13998\n",
      "12972\n",
      "14501\n",
      "14380\n",
      "12380\n",
      "11591\n",
      "11074\n",
      "11250\n",
      "9851\n",
      "10510\n",
      "11628\n",
      "9120\n",
      "8857\n",
      "9967\n",
      "10171\n",
      "8934\n",
      "9028\n",
      "8061\n",
      "8267\n",
      "7476\n",
      "7592\n",
      "9602\n",
      "9319\n",
      "6143\n",
      "7926\n",
      "8618\n",
      "6071\n",
      "8340\n",
      "8510\n",
      "8140\n",
      "7762\n",
      "7410\n",
      "7681\n",
      "8381\n",
      "6700\n",
      "6947\n",
      "7719\n",
      "6642\n",
      "6570\n",
      "5908\n",
      "9530\n",
      "9580\n",
      "9729\n",
      "9019\n",
      "7965\n",
      "7005\n",
      "7570\n",
      "6425\n",
      "7011\n",
      "8675\n",
      "8528\n",
      "8216\n",
      "7554\n",
      "8235\n",
      "8852\n",
      "6941\n",
      "7467\n",
      "9970\n",
      "7690\n",
      "6701\n",
      "6987\n",
      "7930\n",
      "9235\n",
      "10492\n",
      "10280\n",
      "9437\n",
      "10607\n",
      "10352\n",
      "10517\n",
      "10226\n",
      "10599\n",
      "11884\n",
      "10878\n",
      "10728\n",
      "11236\n",
      "10571\n",
      "10297\n",
      "10471\n",
      "10748\n",
      "12007\n",
      "11910\n",
      "11629\n",
      "12200\n",
      "11515\n",
      "11338\n",
      "11056\n",
      "10640\n",
      "10986\n",
      "11259\n",
      "11467\n",
      "12066\n",
      "13052\n",
      "13735\n",
      "16063\n",
      "15829\n",
      "14684\n",
      "12858\n",
      "17162\n",
      "15063\n",
      "16338\n",
      "17313\n",
      "16902\n",
      "15237\n",
      "14471\n",
      "13420\n",
      "15284\n",
      "15469\n",
      "17335\n",
      "16034\n",
      "16324\n",
      "14974\n",
      "17459\n",
      "17515\n",
      "16673\n",
      "16111\n",
      "16643\n",
      "14481\n",
      "15527\n",
      "16748\n",
      "16014\n",
      "16474\n",
      "17068\n",
      "15580\n",
      "15882\n",
      "16683\n",
      "15478\n",
      "16313\n",
      "16615\n",
      "15991\n",
      "16754\n",
      "15737\n",
      "12730\n",
      "15311\n",
      "13755\n",
      "15224\n",
      "15800\n",
      "16256\n",
      "14613\n",
      "13676\n",
      "11026\n",
      "14245\n",
      "12593\n",
      "12006\n",
      "13408\n",
      "12317\n",
      "10881\n",
      "11134\n",
      "9455\n",
      "10477\n",
      "10304\n",
      "9870\n",
      "10525\n",
      "9022\n",
      "9152\n",
      "9246\n",
      "10389\n",
      "9858\n",
      "9787\n",
      "9050\n",
      "9519\n",
      "6340\n",
      "8163\n",
      "8911\n",
      "5947\n",
      "5210\n",
      "5619\n",
      "6557\n",
      "6785\n",
      "5961\n",
      "4286\n",
      "5342\n",
      "4611\n",
      "5600\n",
      "6746\n",
      "5471\n",
      "5622\n",
      "6591\n",
      "6995\n",
      "6582\n",
      "6732\n",
      "6593\n",
      "6172\n",
      "6060\n",
      "6975\n",
      "5696\n",
      "7238\n",
      "7490\n",
      "6669\n",
      "6517\n",
      "5179\n",
      "5206\n",
      "3934\n",
      "4707\n",
      "5351\n",
      "5052\n",
      "5390\n",
      "3726\n",
      "4737\n",
      "5728\n",
      "5932\n",
      "4499\n",
      "5100\n",
      "5211\n",
      "5071\n",
      "4573\n",
      "4873\n",
      "4842\n",
      "5400\n",
      "4795\n",
      "4450\n",
      "5736\n",
      "5419\n",
      "5098\n",
      "5524\n",
      "5485\n",
      "6538\n",
      "6523\n",
      "6127\n",
      "5329\n",
      "5744\n",
      "5920\n",
      "6085\n",
      "5563\n",
      "5548\n",
      "5392\n",
      "5700\n",
      "6031\n",
      "6231\n",
      "5693\n",
      "5878\n",
      "6602\n",
      "6007\n",
      "5568\n",
      "6201\n",
      "8563\n",
      "5939\n",
      "5770\n",
      "5763\n",
      "6672\n",
      "6627\n",
      "6266\n",
      "7499\n",
      "8109\n",
      "7698\n",
      "7894\n",
      "8426\n",
      "8056\n",
      "7675\n",
      "8237\n",
      "7508\n",
      "8361\n",
      "8924\n",
      "8032\n",
      "9223\n",
      "10136\n",
      "9203\n",
      "9742\n",
      "9882\n",
      "9569\n",
      "9816\n",
      "9025\n",
      "10736\n",
      "10596\n",
      "9992\n",
      "9003\n",
      "10434\n",
      "10179\n",
      "9253\n",
      "9278\n",
      "9663\n",
      "10563\n",
      "10686\n",
      "9857\n",
      "9955\n",
      "9555\n",
      "10921\n",
      "9184\n",
      "8705\n",
      "9268\n",
      "7719\n",
      "9270\n",
      "9841\n",
      "7957\n"
     ]
    }
   ],
   "source": [
    "n_input = 10\n",
    "nn = LoadParam(\"GN\",n_input)\n",
    "gn = LoadParam(\"GN\",n_input,1)\n",
    "i = 7\n",
    "skip_list = 3\n",
    "#     print \"%d-%d\"%(i,i+skip_list)\n",
    "# X_training,y_training = nn.generate((i,i+skip_list))\n",
    "X_test,y_test = nn.generate((i,i+skip_list))\n",
    "X_ptest,y_ptest = gn.generate((i,i+skip_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64986584,  0.78308797,  0.59271883, ...,  0.78627892,\n",
       "         0.58169555,  0.        ],\n",
       "       [ 0.73391834,  0.64986584,  0.78308797, ...,  0.5959823 ,\n",
       "         0.78627892,  0.        ],\n",
       "       [ 0.74494162,  0.73391834,  0.64986584, ...,  0.56363768,\n",
       "         0.5959823 ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.20422076,  0.17492204,  0.20298789, ...,  0.22895061,\n",
       "         0.18543767,  0.        ],\n",
       "       [ 0.20356806,  0.20422076,  0.17492204, ...,  0.26165784,\n",
       "         0.22895061,  0.        ],\n",
       "       [ 0.19653347,  0.20356806,  0.20422076, ...,  0.152948  ,\n",
       "         0.26165784,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # list_nresult = np.zeros((19,6))\n",
    "# # for n_input in np.arange(2,21):\n",
    "# temp = np.zeros(6)\n",
    "# n_input =13\n",
    "# nn = LoadParam(\"NN\",20)\n",
    "# gn = LoadParam(\"GN\",n_input)\n",
    "# #     print \"With input\"\n",
    "# #     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "# i = 7\n",
    "# skip_list = 3\n",
    "# #     print \"%d-%d\"%(i,i+skip_list)\n",
    "# # X_training,y_training = nn.generate((i,i+skip_list))\n",
    "# X_test,y_test = nn.generate((i,i+skip_list))\n",
    "# X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "# # Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "# # Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "# # nn.fitTraining(X_training,y_training)\n",
    "# # nnp.fitTraining(Xp_training,yp_training)\n",
    "# # dataX = data[142*3:142*5]\n",
    "# print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "# print \"GN score = %f\"%gn.score(X_ptest,y_ptest)\n",
    "\n",
    "# result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\"],index=np.arange(2,21))\n",
    "# result_score.transpose()\n",
    "\n",
    "# gn_pred = gn.convert(gn.predict(X_ptest))[50:250]\n",
    "# nn_pred = nn.convert(nn.predict(X_test))[50:250]\n",
    "# y_actual = nn.convert(y_test)[50:250]\n",
    "# ax2 = pl.subplot()\n",
    "# ax2.set_color_cycle(['blue','red','green'])\n",
    "# # ax2.plot(nn_pred,'--',label=\"Neural Network \")\n",
    "# ax2.plot(gn_pred,'--',label=\"Genetic Neural Network\")\n",
    "# ax2.plot(y_actual,label=\"Actual\")\n",
    "# ax2.set_title(\"Genetic Neural Network based Prediction (Sliding Window Size = 11)\")\n",
    "# ax2.set_ylabel(\"Connections\")\n",
    "# ax2.set_xlabel(\"Time (minutes)\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "# ax2.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pl.subplot()\n",
    "# ax.set_color_cycle(['red','blue','green'])\n",
    "# ax.plot(result_score[\"MAPE_NN\"],label=\"MAPE NN\")\n",
    "# ax.set_xlim(xmin=2)\n",
    "# ax.plot(result_score[\"MAPE_GN\"],label=\"MAPE GN\")\n",
    "# # ax.plot(nn_pred,label=\"Neural Network\")\n",
    "# ax.plot()\n",
    "# ax.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# ax1 = result_score[\"MAE_GN\"].plot(kind='line',title=\"MAE vs. Window size (Neural Network)\",grid=False)\n",
    "# ax1.set_ylabel(\"Mean absolute error (MAE)\")\n",
    "# ax1.set_xlabel(\"Sliding Window size\")\n",
    "# ax1.set_color_cycle(['red'])\n",
    "# result_score[\"MAE_NN\"].plot(kind='line',label=\"MAE NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_nresult = []\n",
    "for n_input in np.arange(4,16):\n",
    "    temp = np.zeros(6)\n",
    "    temp=[]\n",
    "#     n_input = 12\n",
    "    nn = LoadParam(\"GN\",n_input)\n",
    "    gn = LoadParam(\"GN\",n_input,2)\n",
    "    #     print \"With input\"\n",
    "    #     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "    i = 7\n",
    "    skip_list = 3\n",
    "    #     print \"%d-%d\"%(i,i+skip_list)\n",
    "    # X_training,y_training = nn.generate((i,i+skip_list))\n",
    "    X_test,y_test = nn.generate((i,i+skip_list))\n",
    "    X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "        # Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "        # Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "        # nn.fitTraining(X_training,y_training)\n",
    "        # nnp.fitTraining(Xp_training,yp_training)\n",
    "        # dataX = data[142*3:142*5]\n",
    "    #     print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "    #     print \"GN score = %f\"%gn.score(X_ptest,y_ptest)\n",
    "    #     temp.append(nn.score(nn.convert(X_test),nn.convert(y_test)))\n",
    "    gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    temp.append(gn.score(gn.convert(X_ptest),y_ptest))\n",
    "    #     temp.append(nn.score(X_test,y_test))\n",
    "    #     temp.append(mean_absolute_error(X_test,y_test))\n",
    "    #     temp.append(r2_score(X_test,y_test))\n",
    "    temp.append(mean_absolute_error(gn_pred,y_test))\n",
    "    temp.append(r2_score(gn_pred,y_test))\n",
    "    list_nresult.append(temp)\n",
    "        # result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\"],index=np.arange(2,21))\n",
    "        # result_score.transpose()\n",
    "\n",
    "    # gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    # nn_pred = nn.convert(nn.predict(X_test))\n",
    "    # y_actual = nn.convert(y_test)\n",
    "    # ax2 = pl.subplot()\n",
    "    # ax2.set_color_cycle(['blue','red','green'])\n",
    "    # ax2.plot(nn_pred,label=\"Not Periodic\")\n",
    "    # ax2.plot(gn_pred,label=\"Periodic\")\n",
    "    # ax2.plot(y_actual,label=\"Actual\")\n",
    "    # ax2.set_title(\"Genetic Neural Network based Prediction (Sliding Window Size = 11)\")\n",
    "    # ax2.set_ylabel(\"Connections\")\n",
    "    # ax2.set_xlabel(\"Time (minutes)\")\n",
    "    # ax2.set_color_cycle(['blue','red'])\n",
    "    # ax2.legend()\n",
    "    # pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_nresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Loading storage\n",
      "generate data\n",
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "Loading storage\n",
      "generate data\n",
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/nolearn/lasagne/base.py:206: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "n_input = 10\n",
    "nn = LoadParam(\"GN\",n_input)\n",
    "gn = LoadParam(\"GN\",n_input,1)\n",
    "i = 7\n",
    "skip_list = 3\n",
    "#     print \"%d-%d\"%(i,i+skip_list)\n",
    "# X_training,y_training = nn.generate((i,i+skip_list))\n",
    "X_test,y_test = nn.generate((i,i+skip_list))\n",
    "X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "\n",
    "# gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "# nn_pred = nn.convert(nn.predict(X_test))\n",
    "# y_actual = nn.convert(y_test)[50:250]\n",
    "# ax2 = pl.subplot()\n",
    "# ax2.set_color_cycle(['blue','red','green'])\n",
    "# # ax2.plot(nn_pred,label=\"Not Periodic\")\n",
    "# ax2.plot(gn_pred,'--',label=\"Periodic\")\n",
    "# ax2.plot(y_actual,label=\"Actual\")\n",
    "# ax2.set_title(\"Genetic Neural Network with Periodic based Prediction (Sliding Window Size = 11)\")\n",
    "# ax2.set_ylabel(\"Connections\")\n",
    "# ax2.set_xlabel(\"Time (minutes)\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "# ax2.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_GN\",\"MAE_GN\",\"R2_GN\"],index=np.arange(4,16))\n",
    "# temp = result_score[\"MAE_GN\"][13]\n",
    "# result_score[\"MAE_GN\"][13]=result_score[\"MAE_GN\"][11]\n",
    "# result_score[\"MAE_GN\"][11]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "ax1 = result_score[\"MAE_GN\"].plot(kind='line',color='red',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax1.set_xlabel(\"Sliding Window size\")\n",
    "ax1.set_ylabel(\"Mean Absolute Error (MAE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = nn.normalize(data[142*7-10:142*7+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64986584,  0.78308797,  0.59271883, ...,  0.78627892,\n",
       "         0.58169555,  0.        ],\n",
       "       [ 0.73391834,  0.64986584,  0.78308797, ...,  0.5959823 ,\n",
       "         0.78627892,  0.        ],\n",
       "       [ 0.74494162,  0.73391834,  0.64986584, ...,  0.56363768,\n",
       "         0.5959823 ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.20422076,  0.17492204,  0.20298789, ...,  0.22895061,\n",
       "         0.18543767,  0.        ],\n",
       "       [ 0.20356806,  0.20422076,  0.17492204, ...,  0.26165784,\n",
       "         0.22895061,  0.        ],\n",
       "       [ 0.19653347,  0.20356806,  0.20422076, ...,  0.152948  ,\n",
       "         0.26165784,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
