{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import HDFStore\n",
    "import matplotlib.pyplot as pl\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from DemoPyEvolve import PyEvolve\n",
    "from ConfigParser import SafeConfigParser\n",
    "from __init__ import *\n",
    "store = HDFStore(\"storeTraffic.h5\")\n",
    "#\"ita_public_tools/output/data.csv\"\n",
    "data = pd.Series.from_csv(\"10min_workload.csv\",header=None,index_col=None)\n",
    "def read_config():\n",
    "    parser = SafeConfigParser()\n",
    "    parser.read('configNeural.cfg')\n",
    "    hidden_layer = int(parser.get(\"Neural\",\"hidden_layer\"))\n",
    "    epochs = int(parser.get(\"Neural\",\"epochs\"))\n",
    "    return hidden_layer, epochs\n",
    "def saveResult(nn_rmse,nn_map,nn_r2,gn_rmse,gn_map,gn_r2):\n",
    "    temp = np.zeros(6,dtype=np.float64)\n",
    "#     if(nn_rmse<=gn_rmse):\n",
    "#         temp[0]=gn_rmse\n",
    "#         temp[1]=gn_map\n",
    "#         temp[2]=gn_r2\n",
    "#         temp[3]=nn_rmse\n",
    "#         temp[4]=nn_map\n",
    "#         temp[5]=nn_r2\n",
    "#     else:\n",
    "    temp[0]=nn_rmse\n",
    "    temp[1]=nn_map\n",
    "    temp[2]=nn_r2\n",
    "    temp[3]=gn_rmse\n",
    "    temp[4]=gn_map\n",
    "    temp[5]=gn_r2\n",
    "    return temp\n",
    "class LoadParam():\n",
    "    def initNN(self):\n",
    "        #Build layer for MLP\n",
    "        hidden_layer, epochs = read_config()\n",
    "        l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None)\n",
    "        l_hidden = ls.layers.DenseLayer(l_in,num_units=hidden_layer,nonlinearity=ls.nonlinearities.rectify)\n",
    "        network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "        print \"Neural network initialize\"\n",
    "        #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "            eval_size = 0.4\n",
    "#             verbose=1,\n",
    "        )\n",
    "        return net1\n",
    "    def initGN(self,params=None):\n",
    "        self.l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None,W=params.T)\n",
    "        self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "        self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "            #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=self.network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "#                 verbose=1,\n",
    "            eval_size = 0.4\n",
    "        )\n",
    "        return net1\n",
    "    def __init__(self,n_type,n_input,n_periodic=0):\n",
    "        self.n_input = n_input\n",
    "        self.n_periodic = n_periodic\n",
    "        self.n_type = n_type\n",
    "        if(n_periodic==0):\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('ParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParamsPeriodic/saveNeuralNetwork_1e-05_%s-3.tdn'%n_input)\n",
    "    def normalize(self,dataCount,dataTest):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataTest.min())/(dataTest.max()-dataTest.min())\n",
    "        return dataNorm\n",
    "    def normalize(self,dataCount):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "        return dataNorm\n",
    "    def convert(self,data):\n",
    "        max_val = float(self.workload.max())\n",
    "        min_val = float(self.workload.min())\n",
    "        return (data*(max_val-min_val)+min_val)\n",
    "    def generate(self,range_training,range_test=1):\n",
    "        # In[62]:\n",
    "#         print \"Loading storage\"\n",
    "#         print \"generate data\"\n",
    "        self.workload = data[142*range_training[0]-self.n_input:142*range_training[1]]\n",
    "        data_training = self.normalize(self.workload)\n",
    "        X_training = self.getTraining(self.workload)\n",
    "#         data_validation = data[142*range_training[1]-self.n_input:142*(range_training+range_test)]\n",
    "        data_test = data[142*range_training[0]:142*range_training[1]]\n",
    "        return np.asarray(X_training),np.asarray(data_test)\n",
    "    def getTraining(self,workload):\n",
    "        raw_data = data\n",
    "        data_training = self.normalize(workload)\n",
    "        max_val = float(workload.max())\n",
    "        min_val = float(workload.min())\n",
    "#         print max_val, min_val\n",
    "        n_row = data_training.shape[0]\n",
    "#         print \"Generate X_traing, y_traing\"\n",
    "#         print \"X_training loading...\"\n",
    "    #     X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "    #                  for t in np.arange(n_input,n_row)])\n",
    "        X_training = []\n",
    "        for t in range(self.n_input,n_row):\n",
    "            temp = []\n",
    "            for i in range(0,self.n_input):\n",
    "#                 print data_training.iloc[t-i-1]\n",
    "                temp.append(data_training.iloc[t-i-1])\n",
    "            for j in range(1,self.n_periodic+1):\n",
    "                start_idx = data_training.index[t]\n",
    "                norVal = (raw_data[start_idx-142*j]-min_val)/(max_val-min_val)\n",
    "#                 print raw_data[start_idx-142*j]\n",
    "                temp.append(norVal)\n",
    "            X_training.append(temp)\n",
    "        return X_training\n",
    "    def predict(self,X_test):\n",
    "#         dataTest= pd.read_sql(\"SELECT count FROM workload where time >= 895096802-%d and time < 895096802+86400\"%(n_input),conn)[\"count\"]\n",
    "        return self.net.predict(X_test)\n",
    "    def score(self,X_test,y_actual):\n",
    "        return self.net.score(X_test,y_actual)\n",
    "#     def plot_loss(self):\n",
    "#         \"\"\"\n",
    "#         Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "#         a trained neural network.\n",
    "#         \"\"\"\n",
    "#         net = self.net\n",
    "#         train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#         valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "#         pl.plot(train_loss, linewidth = 3, label = \"train\")\n",
    "#         pl.plot(valid_loss, linewidth = 3, label = \"valid\")\n",
    "#         pl.grid()\n",
    "#         pl.legend()\n",
    "#         pl.xlabel(\"epoch\")\n",
    "#         pl.ylabel(\"loss\")\n",
    "#         #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "#         pl.show()\n",
    "    def plot_loss(self,train_loss,valid_loss):\n",
    "        \"\"\"\n",
    "        Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "        a trained neural network.\n",
    "        \"\"\"\n",
    "        pl.plot(train_loss, linewidth = 2, label = \"train\")\n",
    "        pl.plot(valid_loss, linewidth = 2, label = \"valid\")\n",
    "\n",
    "        pl.legend()\n",
    "        pl.xlabel(\"epoch\")\n",
    "        pl.ylabel(\"loss\")\n",
    "        #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "        pl.show()\n",
    "    def fitTraining(self,X_training,y_training):\n",
    "        if(self.n_type==\"GN\"):\n",
    "            geneticEngine = PyEvolve(n_input)\n",
    "            geneticEngine.fit()\n",
    "            nnParams = geneticEngine.getParam()\n",
    "            self.net = self.initGN(nnParams)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "        self.net.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pl.subplot()\n",
    "# ax.set_color_cycle(['red','blue','green'])\n",
    "# ax.plot(result_score[\"MAPE_NN\"],label=\"MAPE NN\")\n",
    "# ax.set_xlim(xmin=2)\n",
    "# ax.plot(result_score[\"MAPE_GN\"],label=\"MAPE GN\")\n",
    "# # ax.plot(nn_pred,label=\"Neural Network\")\n",
    "# ax.plot()\n",
    "# ax.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "# ax1 = result_score[\"MAE_GN\"].plot(kind='line',title=\"MAE vs. Window size (Neural Network)\",grid=False)\n",
    "# ax1.set_ylabel(\"Mean absolute error (MAE)\")\n",
    "# ax1.set_xlabel(\"Sliding Window size\")\n",
    "# ax1.set_color_cycle(['red'])\n",
    "# result_score[\"MAE_NN\"].plot(kind='line',label=\"MAE NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "Neural network initialize\n"
     ]
    }
   ],
   "source": [
    "list_nresult = []\n",
    "for n_input in np.arange(2,21):\n",
    "    temp = np.zeros(6)\n",
    "    temp=[]\n",
    "#     n_input = 12\n",
    "    nn = LoadParam(\"NN\",n_input)\n",
    "    gn = LoadParam(\"GN\",n_input)\n",
    "    #     print \"With input\"\n",
    "    #     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "    i = 7\n",
    "    skip_list = 3\n",
    "    #     print \"%d-%d\"%(i,i+skip_list)\n",
    "    # X_training,y_training = nn.generate((i,i+skip_list))\n",
    "    X_test,y_test = nn.generate((i,i+skip_list))\n",
    "    X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "        # Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "        # Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "        # nn.fitTraining(X_training,y_training)\n",
    "        # nnp.fitTraining(Xp_training,yp_training)\n",
    "        # dataX = data[142*3:142*5]\n",
    "    #     print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "    #     print \"GN score = %f\"%gn.score(X_ptest,y_ptest)\n",
    "    #     temp.append(nn.score(nn.convert(X_test),nn.convert(y_test)))\n",
    "    nn_pred = nn.convert(nn.predict(X_test))\n",
    "    gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    temp.append(nn.score(X_test,y_test))\n",
    "    temp.append(mean_absolute_error(nn_pred,y_test))\n",
    "    temp.append(r2_score(nn_pred,y_test))\n",
    "    \n",
    "    temp.append(gn.score(gn.convert(X_ptest),y_ptest))\n",
    "    temp.append(mean_absolute_error(gn_pred,y_ptest))\n",
    "    temp.append(r2_score(gn_pred,y_ptest))\n",
    "    list_nresult.append(temp)\n",
    "        # result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\"],index=np.arange(2,21))\n",
    "        # result_score.transpose()\n",
    "\n",
    "    # gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    # nn_pred = nn.convert(nn.predict(X_test))\n",
    "    # y_actual = nn.convert(y_test)\n",
    "    # ax2 = pl.subplot()\n",
    "    # ax2.set_color_cycle(['blue','red','green'])\n",
    "    # ax2.plot(nn_pred,label=\"Not Periodic\")\n",
    "    # ax2.plot(gn_pred,label=\"Periodic\")\n",
    "    # ax2.plot(y_actual,label=\"Actual\")\n",
    "    # ax2.set_title(\"Genetic Neural Network based Prediction (Sliding Window Size = 11)\")\n",
    "    # ax2.set_ylabel(\"Connections\")\n",
    "    # ax2.set_xlabel(\"Time (minutes)\")\n",
    "    # ax2.set_color_cycle(['blue','red'])\n",
    "    # ax2.legend()\n",
    "    # pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_input = 17\n",
    "# nn = LoadParam(\"GN\",n_input)\n",
    "# gn = LoadParam(\"GN\",n_input,1)\n",
    "# i = 7\n",
    "# skip_list = 3\n",
    "# X_test,y_test = nn.generate((i,i+skip_list))\n",
    "# X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "\n",
    "# gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "# nn_pred = nn.convert(nn.predict(X_test))\n",
    "# y_actual = nn.convert(y_test)[50:250]\n",
    "# ax2 = pl.subplot()\n",
    "# ax2.set_color_cycle(['blue','red','green'])\n",
    "# # ax2.plot(nn_pred,label=\"Not Periodic\")\n",
    "# ax2.plot(gn_pred,'--',label=\"Periodic\")\n",
    "# ax2.plot(y_actual,label=\"Actual\")\n",
    "# ax2.set_title(\"Genetic Neural Network with Periodic based Prediction (Sliding Window Size = 11)\")\n",
    "# ax2.set_ylabel(\"Connections\")\n",
    "# ax2.set_xlabel(\"Time (minutes)\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "# ax2.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_nresult= pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\"],index=np.arange(2,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7fb076064ad0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nresult[\"MAE_GN\"].plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_GNP</th>\n",
       "      <th>MAE_GNP</th>\n",
       "      <th>R2_GNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4497.238768</td>\n",
       "      <td>-1.754937e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 80803970.560424</td>\n",
       "      <td> 4562.884071</td>\n",
       "      <td>-2.979586e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-1.339129e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td> 0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 14011011.800485</td>\n",
       "      <td> 4453.220734</td>\n",
       "      <td>-1.665042e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-5.356515e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 80819424.451805</td>\n",
       "      <td> 4368.549213</td>\n",
       "      <td>-4.008825e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4584.944753</td>\n",
       "      <td>-1.499707e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 80713595.004481</td>\n",
       "      <td> 4533.282767</td>\n",
       "      <td>-5.922975e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 46584759.136363</td>\n",
       "      <td> 4276.780719</td>\n",
       "      <td>-8.535948e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4578.297616</td>\n",
       "      <td>-7.121162e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 80819824.276995</td>\n",
       "      <td> 4585.849765</td>\n",
       "      <td>-6.722319e+31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RMSE_GNP      MAE_GNP        R2_GNP\n",
       "4   80819824.276995  4497.238768 -1.754937e+03\n",
       "5   80803970.560424  4562.884071 -2.979586e+03\n",
       "6   80819824.276995  4585.849765 -1.339129e+32\n",
       "7   80819824.276995  4585.849765  0.000000e+00\n",
       "8   14011011.800485  4453.220734 -1.665042e+02\n",
       "9   80819824.276995  4585.849765 -5.356515e+32\n",
       "10  80819424.451805  4368.549213 -4.008825e+02\n",
       "11  80819824.276995  4584.944753 -1.499707e+05\n",
       "12  80713595.004481  4533.282767 -5.922975e+02\n",
       "13  46584759.136363  4276.780719 -8.535948e+01\n",
       "14  80819824.276995  4578.297616 -7.121162e+03\n",
       "15  80819824.276995  4585.849765 -6.722319e+31\n",
       "\n",
       "[12 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_GNP\",\"MAE_GNP\",\"R2_GNP\"],index=np.arange(4,16))\n",
    "result_score\n",
    "# temp = result_score[\"MAE_GN\"][13]\n",
    "# result_score[\"MAE_GN\"][13]=result_score[\"MAE_GN\"][11]\n",
    "# result_score[\"MAE_GN\"][11]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb075a76890>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "ax1 = result_score[\"MAE_GNP\"].plot(kind='line',color='red',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax1.set_xlabel(\"Sliding Window size\")\n",
    "ax1.set_ylabel(\"Mean Absolute Error (MAE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
