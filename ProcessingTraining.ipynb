{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pandas import HDFStore\n",
    "import matplotlib.pyplot as pl\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from DemoPyEvolve import PyEvolve\n",
    "from ConfigParser import SafeConfigParser\n",
    "from __init__ import *\n",
    "store = HDFStore(\"storeTraffic.h5\")\n",
    "#\"ita_public_tools/output/data.csv\"\n",
    "data = pd.Series.from_csv(\"10min_workload.csv\",header=None,index_col=None)\n",
    "def read_config():\n",
    "    parser = SafeConfigParser()\n",
    "    parser.read('configNeural.cfg')\n",
    "    hidden_layer = int(parser.get(\"Neural\",\"hidden_layer\"))\n",
    "    epochs = int(parser.get(\"Neural\",\"epochs\"))\n",
    "    return hidden_layer, epochs\n",
    "class LoadParam():\n",
    "    def initNN(self):\n",
    "        #Build layer for MLP\n",
    "        hidden_layer, epochs = read_config()\n",
    "        l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None)\n",
    "        l_hidden = ls.layers.DenseLayer(l_in,num_units=hidden_layer,nonlinearity=ls.nonlinearities.rectify)\n",
    "        network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "        print \"Neural network initialize\"\n",
    "        #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "            eval_size = 0.4\n",
    "#             verbose=1,\n",
    "        )\n",
    "        return net1\n",
    "    def initGN(self,params=None):\n",
    "        self.l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None,W=params.T)\n",
    "        self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "        self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "            #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=self.network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "#                 verbose=1,\n",
    "            eval_size = 0.4\n",
    "        )\n",
    "        return net1\n",
    "    def __init__(self,n_type,n_input,n_periodic=0):\n",
    "        self.n_input = n_input\n",
    "        self.n_periodic = n_periodic\n",
    "        self.n_type = n_type\n",
    "        if(n_periodic==0):\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('ParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "    def normalize(self,dataCount,dataTest):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataTest.min())/(dataTest.max()-dataTest.min())\n",
    "        return dataNorm\n",
    "    def normalize(self,dataCount):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "        return dataNorm\n",
    "    def convert(self,data):\n",
    "        max_val = self.workload.max()\n",
    "        min_val = self.workload.min()\n",
    "        return (data*(max_val-min_val)+min_val)\n",
    "    def generate(self,range_training,range_test=1):\n",
    "        # In[62]:\n",
    "        print \"Loading storage\"\n",
    "        print \"generate data\"\n",
    "        self.workload = data[142*range_training[0]-self.n_input:142*range_training[1]]\n",
    "        data_training = self.normalize(self.workload)\n",
    "        X_training = self.getTraining(data_training)\n",
    "#         data_validation = data[142*range_training[1]-self.n_input:142*(range_training+range_test)]\n",
    "        data_test = self.normalize(data[142*range_training[0]:142*range_training[1]])\n",
    "        return np.asarray(X_training),np.asarray(data_test)\n",
    "    def getTraining(self,data_training):\n",
    "        raw_data = store[\"raw_data_conn\"]\n",
    "        n_row = data_training.shape[0]\n",
    "        print \"Generate X_traing, y_traing\"\n",
    "        print \"X_training loading...\"\n",
    "    #     X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "    #                  for t in np.arange(n_input,n_row)])\n",
    "        X_training = []\n",
    "        for t in range(self.n_input,n_row):\n",
    "            temp = []\n",
    "            for i in range(0,self.n_input):\n",
    "                temp.append(data_training.iloc[t-i-1])\n",
    "            for j in range(1,self.n_periodic+1):\n",
    "                start_idx = data_training.index[t]\n",
    "                temp.append(raw_data[start_idx-142*j])\n",
    "            X_training.append(temp)\n",
    "        return X_training\n",
    "    def predict(self,X_test):\n",
    "#         dataTest= pd.read_sql(\"SELECT count FROM workload where time >= 895096802-%d and time < 895096802+86400\"%(n_input),conn)[\"count\"]\n",
    "        return self.net.predict(X_test)\n",
    "    def score(self,X_test,y_actual):\n",
    "        return self.net.score(X_test,y_actual)\n",
    "#     def plot_loss(self):\n",
    "#         \"\"\"\n",
    "#         Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "#         a trained neural network.\n",
    "#         \"\"\"\n",
    "#         net = self.net\n",
    "#         train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#         valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "#         pl.plot(train_loss, linewidth = 3, label = \"train\")\n",
    "#         pl.plot(valid_loss, linewidth = 3, label = \"valid\")\n",
    "#         pl.grid()\n",
    "#         pl.legend()\n",
    "#         pl.xlabel(\"epoch\")\n",
    "#         pl.ylabel(\"loss\")\n",
    "#         #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "#         pl.show()\n",
    "    def plot_loss(self,train_loss,valid_loss):\n",
    "        \"\"\"\n",
    "        Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "        a trained neural network.\n",
    "        \"\"\"\n",
    "        pl.plot(train_loss, linewidth = 2, label = \"train\")\n",
    "        pl.plot(valid_loss, linewidth = 2, label = \"valid\")\n",
    "\n",
    "        pl.legend()\n",
    "        pl.xlabel(\"epoch\")\n",
    "        pl.ylabel(\"loss\")\n",
    "        #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "        pl.show()\n",
    "    def fitTraining(self,X_training,y_training):\n",
    "        if(self.n_type==\"GN\"):\n",
    "            geneticEngine = PyEvolve(n_input)\n",
    "            geneticEngine.fit()\n",
    "            nnParams = geneticEngine.getParam()\n",
    "            self.net = self.initGN(nnParams)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "        self.net.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Neural network initialize\n",
      "Neural network initialize\n",
      "3-5\n",
      "Loading storage\n",
      "generate data\n",
      "Generate X_traing, y_traing\n",
      "X_training loading...\n",
      "NN score = 0.005393\n",
      "GN score = 0.006937\n"
     ]
    }
   ],
   "source": [
    "n_input = 13\n",
    "print n_input\n",
    "nn = LoadParam(\"NN\",n_input,1)\n",
    "gn = LoadParam(\"GN\",n_input,1)\n",
    "#     print \"With input\"\n",
    "#     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "i = 3\n",
    "skip_list = 2\n",
    "print \"%d-%d\"%(i,i+skip_list)\n",
    "# X_training,y_training = nn.generate((i,i+skip_list))\n",
    "X_test,y_test = nn.generate((i,i+skip_list))\n",
    "\n",
    "# Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "# Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "# nn.fitTraining(X_training,y_training)\n",
    "# nnp.fitTraining(Xp_training,yp_training)\n",
    "# dataX = data[142*3:142*5]\n",
    "print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "print \"GN score = %f\"%gn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_loss = np.array([i[\"train_loss\"] for i in nn.net.train_history_])\n",
    "# valid_loss = np.array([i[\"train_loss\"] for i in nnp.net.train_history_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pl.subplot()\n",
    "# # ax.plot(train_loss,label=\"train loss nn\")\n",
    "# ax.plot(valid_loss,label=\"train_loss gn\")\n",
    "# ax.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workload = nn.workload\n",
    "gn_pred = nn.convert(gn.predict(X_test))\n",
    "nn_pred = nn.convert(nn.predict(X_test))\n",
    "y_actual = nn.convert(y_test)\n",
    "ax = pl.subplot()\n",
    "ax.set_color_cycle(['red','blue','green'])\n",
    "ax.plot(gn_pred,label=\"Genetic Neural Network\")\n",
    "# ax.plot(nn_pred,label=\"Neural Network\")\n",
    "ax.set_title(\"Genetic Neural Network\")\n",
    "ax.plot(y_actual,'--',label=\"Actual\")\n",
    "ax.plot()\n",
    "ax.legend()\n",
    "# ax1.plot(GN.y_training)\n",
    "# ax1.legend([\"Predict\",\"Actual\"])\n",
    "# # ax1.set_color_cycle(['blue','red'])\n",
    "# ax2.plot(nn_pred,label=\"Neural Network\")\n",
    "# ax2.plot(NN.y_training)\n",
    "# ax2.set_title(\"Neural Network\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storeNN = HDFStore(\"storeResultNN.h5\")\n",
    "storeGN = HDFStore(\"storeResultGN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_scoreNN = storeNN[\"results_nn\"]\n",
    "raw_scoreGN = storeGN[\"results_gn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pl.subplot()\n",
    "ax.set_color_cycle(['red','blue','green'])\n",
    "ax.plot(raw_scoreNN[\"MAPE\"],label=\"MAPE\")\n",
    "# ax.plot(nn_pred,label=\"Neural Network\")\n",
    "ax.plot()\n",
    "ax.legend()\n",
    "# ax1.plot(GN.y_training)\n",
    "# ax1.legend([\"Predict\",\"Actual\"])\n",
    "# # ax1.set_color_cycle(['blue','red'])\n",
    "# ax2.plot(nn_pred,label=\"Neural Network\")\n",
    "# ax2.plot(NN.y_training)\n",
    "# ax2.set_title(\"Neural Network\")\n",
    "# ax2.set_color_cycle(['blue','red'])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td> 0.097444</td>\n",
       "      <td> 0.291202</td>\n",
       "      <td> 0.176841</td>\n",
       "      <td> 0.292115</td>\n",
       "      <td> 0.070903</td>\n",
       "      <td> 0.293046</td>\n",
       "      <td> 0.251879</td>\n",
       "      <td> 0.060273</td>\n",
       "      <td> 0.007819</td>\n",
       "      <td> 0.090770</td>\n",
       "      <td> 0.269674</td>\n",
       "      <td> 0.092574</td>\n",
       "      <td> 0.093486</td>\n",
       "      <td> 0.144600</td>\n",
       "      <td> 0.297287</td>\n",
       "      <td> 0.163484</td>\n",
       "      <td> 0.015920</td>\n",
       "      <td> 0.116371</td>\n",
       "      <td> 0.299236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td> 0.275135</td>\n",
       "      <td> 0.492059</td>\n",
       "      <td> 0.373418</td>\n",
       "      <td> 0.493155</td>\n",
       "      <td> 0.232423</td>\n",
       "      <td> 0.494285</td>\n",
       "      <td> 0.452536</td>\n",
       "      <td> 0.212954</td>\n",
       "      <td> 0.065806</td>\n",
       "      <td> 0.260395</td>\n",
       "      <td> 0.465842</td>\n",
       "      <td> 0.264560</td>\n",
       "      <td> 0.271200</td>\n",
       "      <td> 0.323579</td>\n",
       "      <td> 0.499452</td>\n",
       "      <td> 0.354961</td>\n",
       "      <td> 0.100883</td>\n",
       "      <td> 0.301422</td>\n",
       "      <td> 0.501780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-0.982141</td>\n",
       "      <td>-4.933260</td>\n",
       "      <td>-2.607570</td>\n",
       "      <td>-4.972120</td>\n",
       "      <td>-0.452202</td>\n",
       "      <td>-5.013908</td>\n",
       "      <td>-4.175669</td>\n",
       "      <td>-0.241159</td>\n",
       "      <td> 0.838610</td>\n",
       "      <td>-0.876391</td>\n",
       "      <td>-4.589385</td>\n",
       "      <td>-0.921565</td>\n",
       "      <td>-0.945381</td>\n",
       "      <td>-2.017005</td>\n",
       "      <td>-5.215204</td>\n",
       "      <td>-2.425806</td>\n",
       "      <td> 0.665793</td>\n",
       "      <td>-1.447874</td>\n",
       "      <td>-5.306044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2         3         4         5         6         7         8   \\\n",
       "RMSE  0.097444  0.291202  0.176841  0.292115  0.070903  0.293046  0.251879   \n",
       "MAPE  0.275135  0.492059  0.373418  0.493155  0.232423  0.494285  0.452536   \n",
       "R2   -0.982141 -4.933260 -2.607570 -4.972120 -0.452202 -5.013908 -4.175669   \n",
       "\n",
       "            9         10        11        12        13        14        15  \\\n",
       "RMSE  0.060273  0.007819  0.090770  0.269674  0.092574  0.093486  0.144600   \n",
       "MAPE  0.212954  0.065806  0.260395  0.465842  0.264560  0.271200  0.323579   \n",
       "R2   -0.241159  0.838610 -0.876391 -4.589385 -0.921565 -0.945381 -2.017005   \n",
       "\n",
       "            16        17        18        19        20  \n",
       "RMSE  0.297287  0.163484  0.015920  0.116371  0.299236  \n",
       "MAPE  0.499452  0.354961  0.100883  0.301422  0.501780  \n",
       "R2   -5.215204 -2.425806  0.665793 -1.447874 -5.306044  \n",
       "\n",
       "[3 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_score = raw_scoreGN.transpose()\n",
    "data_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
