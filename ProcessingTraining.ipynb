{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhuan/anaconda2/lib/python2.7/site-packages/Theano-0.8.0.dev0-py2.7.egg/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import HDFStore\n",
    "import matplotlib.pyplot as pl\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from DemoPyEvolve import PyEvolve\n",
    "from ConfigParser import SafeConfigParser\n",
    "from __init__ import *\n",
    "store = HDFStore(\"storeTraffic.h5\")\n",
    "#\"ita_public_tools/output/data.csv\"\n",
    "data = pd.Series.from_csv(\"10min_workload.csv\",header=None,index_col=None)\n",
    "def read_config():\n",
    "    parser = SafeConfigParser()\n",
    "    parser.read('configNeural.cfg')\n",
    "    hidden_layer = int(parser.get(\"Neural\",\"hidden_layer\"))\n",
    "    epochs = int(parser.get(\"Neural\",\"epochs\"))\n",
    "    return hidden_layer, epochs\n",
    "def saveResult(nn_rmse,nn_map,nn_r2,gn_rmse,gn_map,gn_r2):\n",
    "    temp = np.zeros(6,dtype=np.float64)\n",
    "#     if(nn_rmse<=gn_rmse):\n",
    "#         temp[0]=gn_rmse\n",
    "#         temp[1]=gn_map\n",
    "#         temp[2]=gn_r2\n",
    "#         temp[3]=nn_rmse\n",
    "#         temp[4]=nn_map\n",
    "#         temp[5]=nn_r2\n",
    "#     else:\n",
    "    temp[0]=nn_rmse\n",
    "    temp[1]=nn_map\n",
    "    temp[2]=nn_r2\n",
    "    temp[3]=gn_rmse\n",
    "    temp[4]=gn_map\n",
    "    temp[5]=gn_r2\n",
    "    return temp\n",
    "def mean_percentage_error(y_pred,y_actual):\n",
    "    'Calculate the mean percentage absolute error'\n",
    "    n = y_pred.shape[0]\n",
    "    temp = [np.abs((i-j)/j) for i,j in zip(y_pred,y_actual)]\n",
    "    return (1.0/n) * np.sum(temp)\n",
    "class LoadParam():\n",
    "    def initNN(self):\n",
    "        #Build layer for MLP\n",
    "        hidden_layer, epochs = read_config()\n",
    "        l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None)\n",
    "        l_hidden = ls.layers.DenseLayer(l_in,num_units=hidden_layer,nonlinearity=ls.nonlinearities.rectify)\n",
    "        network = l_out = ls.layers.DenseLayer(l_hidden,num_units=1)\n",
    "#         print \"Neural network initialize\"\n",
    "        #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "            eval_size = 0.4\n",
    "#             verbose=1,\n",
    "        )\n",
    "        return net1\n",
    "    def initGN(self,params=None):\n",
    "        self.l_in = ls.layers.InputLayer(shape=(None,self.n_input+self.n_periodic),input_var=None,W=params.T)\n",
    "        self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.rectify)\n",
    "        self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "            #Init Neural net\n",
    "        net1 = NeuralNet(\n",
    "            layers=self.network,\n",
    "            # optimization method:\n",
    "            update=nesterov_momentum,\n",
    "            update_learning_rate=0.000001,\n",
    "            update_momentum=0.9,\n",
    "            regression=True,  # flag to indicate we're dealing with regression problem\n",
    "            max_epochs=800,  # we want to train this many epochs\n",
    "#                 verbose=1,\n",
    "            eval_size = 0.4\n",
    "        )\n",
    "        return net1\n",
    "    def __init__(self,n_type,n_input,n_periodic=0):\n",
    "        self.n_input = n_input\n",
    "        self.n_periodic = n_periodic\n",
    "        self.n_type = n_type\n",
    "        if(n_periodic==0):\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('Params/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "            if(n_type==\"NN\"):\n",
    "                self.net.load_params_from('ParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "            elif(n_type==\"GN\"):\n",
    "                self.net.load_params_from('GeneticParamsPeriodic/saveNeuralNetwork_1e-05_%s.tdn'%n_input)\n",
    "    def normalize(self,dataCount,dataTest):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataTest.min())/(dataTest.max()-dataTest.min())\n",
    "        return dataNorm\n",
    "    def normalize(self,dataCount):\n",
    "        dataNorm = pd.Series(np.zeros(dataCount.shape[0]),dtype=np.float64)\n",
    "        dataNorm = (dataCount - dataCount.min())/(dataCount.max()-dataCount.min())\n",
    "        return dataNorm\n",
    "    def convert(self,data):\n",
    "        max_val = float(self.workload.max())\n",
    "        min_val = float(self.workload.min())\n",
    "        return (data*(max_val-min_val)+min_val)\n",
    "    def generate(self,range_training,range_test=1):\n",
    "        # In[62]:\n",
    "#         print \"Loading storage\"\n",
    "#         print \"generate data\"\n",
    "        self.workload = data[142*range_training[0]-self.n_input:142*range_training[1]]\n",
    "        data_training = self.normalize(self.workload)\n",
    "        X_training = self.getTraining(self.workload)\n",
    "#         data_validation = data[142*range_training[1]-self.n_input:142*(range_training+range_test)]\n",
    "        data_test = data[142*range_training[0]:142*range_training[1]]\n",
    "        return np.asarray(X_training),np.asarray(data_test)\n",
    "    def getTraining(self,workload):\n",
    "        raw_data = data\n",
    "        data_training = self.normalize(workload)\n",
    "        max_val = float(workload.max())\n",
    "        min_val = float(workload.min())\n",
    "#         print max_val, min_val\n",
    "        n_row = data_training.shape[0]\n",
    "#         print \"Generate X_traing, y_traing\"\n",
    "#         print \"X_training loading...\"\n",
    "    #     X_training = np.asarray([[data.iloc[t-i-1] for i in range(0,n_input)]\n",
    "    #                  for t in np.arange(n_input,n_row)])\n",
    "        X_training = []\n",
    "        for t in range(self.n_input,n_row):\n",
    "            temp = []\n",
    "            for i in range(0,self.n_input):\n",
    "#                 print data_training.iloc[t-i-1]\n",
    "                temp.append(data_training.iloc[t-i-1])\n",
    "            for j in range(1,self.n_periodic+1):\n",
    "                start_idx = data_training.index[t]\n",
    "                norVal = (raw_data[start_idx-142*j]-min_val)/(max_val-min_val)\n",
    "#                 print raw_data[start_idx-142*j]\n",
    "                temp.append(norVal)\n",
    "            X_training.append(temp)\n",
    "        return X_training\n",
    "    def predict(self,X_test):\n",
    "#         dataTest= pd.read_sql(\"SELECT count FROM workload where time >= 895096802-%d and time < 895096802+86400\"%(n_input),conn)[\"count\"]\n",
    "        return self.net.predict(X_test)\n",
    "    def score(self,X_test,y_actual):\n",
    "        return self.net.score(X_test,y_actual)\n",
    "#     def plot_loss(self):\n",
    "#         \"\"\"\n",
    "#         Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "#         a trained neural network.\n",
    "#         \"\"\"\n",
    "#         net = self.net\n",
    "#         train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "#         valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "#         pl.plot(train_loss, linewidth = 3, label = \"train\")\n",
    "#         pl.plot(valid_loss, linewidth = 3, label = \"valid\")\n",
    "#         pl.grid()\n",
    "#         pl.legend()\n",
    "#         pl.xlabel(\"epoch\")\n",
    "#         pl.ylabel(\"loss\")\n",
    "#         #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "#         pl.show()\n",
    "    def plot_loss(self,train_loss,valid_loss):\n",
    "        \"\"\"\n",
    "        Plot the training loss and validation loss versus epoch iterations with respect to \n",
    "        a trained neural network.\n",
    "        \"\"\"\n",
    "        pl.plot(train_loss, linewidth = 2, label = \"train\")\n",
    "        pl.plot(valid_loss, linewidth = 2, label = \"valid\")\n",
    "\n",
    "        pl.legend()\n",
    "        pl.xlabel(\"epoch\")\n",
    "        pl.ylabel(\"loss\")\n",
    "        #pyplot.ylim(1e-3, 1e-2)\n",
    "#         pl.yscale(\"log\")\n",
    "        pl.show()\n",
    "    def fitTraining(self,X_training,y_training):\n",
    "        if(self.n_type==\"GN\"):\n",
    "            geneticEngine = PyEvolve(n_input)\n",
    "            geneticEngine.fit()\n",
    "            nnParams = geneticEngine.getParam()\n",
    "            self.net = self.initGN(nnParams)\n",
    "        else:\n",
    "            self.net = self.initNN()\n",
    "        self.net.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhuan/anaconda2/lib/python2.7/site-packages/nolearn-0.6a0.dev0-py2.7.egg/nolearn/lasagne/base.py:250: UserWarning: The 'eval_size' argument has been deprecated, please use the 'train_split' parameter instead, e.g.\n",
      "train_split=TrainSplit(eval_size=0.4)\n",
      "  warn(\"The 'eval_size' argument has been deprecated, please use \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Param'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a1ac40c14ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     n_input = 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoadParam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GN\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mgn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoadParam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GN\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#     print \"With input\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c0a243c46833>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_type, n_input, n_periodic)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_params_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Params/saveNeuralNetwork_1e-05_%s.tdn'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"GN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_params_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GeneticParams/saveNeuralNetwork_1e-05_%s.tdn'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nhuan/anaconda2/lib/python2.7/site-packages/nolearn-0.6a0.dev0-py2.7.egg/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mload_params_from\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_params_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nhuan/anaconda2/lib/python2.7/site-packages/nolearn-0.6a0.dev0-py2.7.egg/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m         iter_funcs = self._create_iter_funcs(\n\u001b[0;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_tensor_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             )\n\u001b[0;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_iter_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_iter_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_funcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nhuan/anaconda2/lib/python2.7/site-packages/nolearn-0.6a0.dev0-py2.7.egg/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36m_create_iter_funcs\u001b[1;34m(self, layers, objective, update, output_type)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         X_inputs = [theano.Param(input_layer.input_var, name=input_layer.name)\n\u001b[1;32m--> 477\u001b[1;33m                     for input_layer in input_layers]\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_inputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'Param'"
     ]
    }
   ],
   "source": [
    "list_nresult = []\n",
    "for n_input in np.arange(2,21):\n",
    "    temp = np.zeros(6)\n",
    "    temp=[]\n",
    "#     n_input = 12\n",
    "    nn = LoadParam(\"GN\",n_input)\n",
    "    gn = LoadParam(\"GN\",n_input,1)\n",
    "    #     print \"With input\"\n",
    "    #     for i in np.arange(1,data[0:142*30].shape[0],1):\n",
    "    i = 46\n",
    "    skip_list = 2\n",
    "    #     print \"%d-%d\"%(i,i+skip_list)\n",
    "    # X_training,y_training = nn.generate((i,i+skip_list))\n",
    "    X_test,y_test = nn.generate((i,i+skip_list))\n",
    "    X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "        # Xp_training,yp_training = nnp.generate((i,i+skip_list))\n",
    "        # Xp_test,yp_test = nnp.generate((i+skip_list+1,i+skip_list+2))\n",
    "        # nn.fitTraining(X_training,y_training)\n",
    "        # nnp.fitTraining(Xp_training,yp_training)\n",
    "        # dataX = data[142*3:142*5]\n",
    "    #     print \"NN score = %f\"%nn.score(X_test,y_test)\n",
    "    #     print \"GN score = %f\"%gn.score(X_ptest,y_ptest)\n",
    "    #     temp.append(nn.score(nn.convert(X_test),nn.convert(y_test)))\n",
    "    nn_pred = nn.convert(nn.predict(X_test))\n",
    "    gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "    \n",
    "    temp.append(np.sqrt(mean_squared_error(nn_pred,y_test)))\n",
    "    temp.append(mean_absolute_error(nn_pred,y_test))\n",
    "    temp.append(r2_score(y_test,nn_pred))\n",
    "    temp.append(mean_percentage_error(y_test,nn_pred))\n",
    "    \n",
    "    temp.append(np.sqrt(mean_squared_error(gn_pred,y_ptest)))\n",
    "    temp.append(mean_absolute_error(gn_pred,y_ptest))\n",
    "    temp.append(r2_score(y_ptest,gn_pred))\n",
    "    temp.append(mean_percentage_error(y_ptest,gn_pred))\n",
    "    \n",
    "    list_nresult.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0.dev0.dev-e891fb3fed4c1522f23a201bda6cfee6cf115e8b'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "theano.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input = 4\n",
    "nn = LoadParam(\"GN\",4)\n",
    "gn = LoadParam(\"GN\",n_input,1)\n",
    "i = 46\n",
    "skip_list = 4\n",
    "X_test,y_test = nn.generate((i,i+skip_list))\n",
    "X_ptest,y_ptest = gn.generate((i,i+skip_list))\n",
    "\n",
    "gn_pred = gn.convert(gn.predict(X_ptest))\n",
    "nn_pred = nn.convert(nn.predict(X_test))\n",
    "y_actual = y_test\n",
    "ax2 = pl.subplot()\n",
    "ax2.set_color_cycle(['blue','red','green'])\n",
    "ax2.plot(nn_pred,'--',label=\"Without Periodic Input\")\n",
    "ax2.plot(gn_pred,'--',label=\"With Periodic Input\")\n",
    "ax2.plot(y_actual,label=\"Actual\")\n",
    "ax2.set_title(\"Genetic Neural Network with Periodic Input based Prediction (Sliding Window Size = 4)\")\n",
    "ax2.set_ylabel(\"Connections\")\n",
    "ax2.set_xlabel(\"Time (minutes)\")\n",
    "ax2.set_color_cycle(['blue','red'])\n",
    "ax2.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes at least 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e9cdb98f2cb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes at least 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "a = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_NN</th>\n",
       "      <th>MAE_NN</th>\n",
       "      <th>R2_NN</th>\n",
       "      <th>MAPE_NN</th>\n",
       "      <th>RMSE_GN</th>\n",
       "      <th>MAE_GN</th>\n",
       "      <th>R2_GN</th>\n",
       "      <th>MAPE_GN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> 328552.299152</td>\n",
       "      <td> 210383.974363</td>\n",
       "      <td>-0.695429</td>\n",
       "      <td> 1.630024</td>\n",
       "      <td>  70656.170502</td>\n",
       "      <td>  33742.822162</td>\n",
       "      <td> 0.921590</td>\n",
       "      <td> 0.071340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> 124019.990982</td>\n",
       "      <td>  79489.201237</td>\n",
       "      <td> 0.758424</td>\n",
       "      <td> 0.225141</td>\n",
       "      <td>  71304.611556</td>\n",
       "      <td>  36076.375865</td>\n",
       "      <td> 0.920144</td>\n",
       "      <td> 0.077698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 104314.704910</td>\n",
       "      <td>  65649.546090</td>\n",
       "      <td> 0.829092</td>\n",
       "      <td> 0.174545</td>\n",
       "      <td>  51738.555057</td>\n",
       "      <td>  26915.557516</td>\n",
       "      <td> 0.957956</td>\n",
       "      <td> 0.061221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 217303.288100</td>\n",
       "      <td> 148541.217068</td>\n",
       "      <td> 0.258343</td>\n",
       "      <td> 0.477888</td>\n",
       "      <td> 328554.336546</td>\n",
       "      <td> 210425.172535</td>\n",
       "      <td>-0.695450</td>\n",
       "      <td> 1.630381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 297306.045762</td>\n",
       "      <td> 175616.015200</td>\n",
       "      <td>-0.388283</td>\n",
       "      <td> 0.984764</td>\n",
       "      <td>  60548.612695</td>\n",
       "      <td>  31186.695624</td>\n",
       "      <td> 0.942419</td>\n",
       "      <td> 0.066647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 123904.541936</td>\n",
       "      <td>  76604.986607</td>\n",
       "      <td> 0.758873</td>\n",
       "      <td> 0.201801</td>\n",
       "      <td>  65850.114461</td>\n",
       "      <td>  32412.832290</td>\n",
       "      <td> 0.931894</td>\n",
       "      <td> 0.067321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 192499.365168</td>\n",
       "      <td> 136252.717521</td>\n",
       "      <td> 0.417992</td>\n",
       "      <td> 0.454460</td>\n",
       "      <td>  59535.709836</td>\n",
       "      <td>  29425.746252</td>\n",
       "      <td> 0.944329</td>\n",
       "      <td> 0.063149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 201280.991082</td>\n",
       "      <td> 133064.109023</td>\n",
       "      <td> 0.363679</td>\n",
       "      <td> 0.423395</td>\n",
       "      <td>  69010.809400</td>\n",
       "      <td>  36011.018284</td>\n",
       "      <td> 0.925199</td>\n",
       "      <td> 0.073061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 175159.795779</td>\n",
       "      <td> 112001.538198</td>\n",
       "      <td> 0.518119</td>\n",
       "      <td> 0.336259</td>\n",
       "      <td>  57834.961503</td>\n",
       "      <td>  30172.344352</td>\n",
       "      <td> 0.947465</td>\n",
       "      <td> 0.067356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 285179.942668</td>\n",
       "      <td> 175536.882830</td>\n",
       "      <td>-0.277346</td>\n",
       "      <td> 0.884263</td>\n",
       "      <td>  73754.053112</td>\n",
       "      <td>  38309.676224</td>\n",
       "      <td> 0.914564</td>\n",
       "      <td> 0.084385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 317660.520365</td>\n",
       "      <td> 188048.841656</td>\n",
       "      <td>-0.584883</td>\n",
       "      <td> 1.380264</td>\n",
       "      <td>  61276.784169</td>\n",
       "      <td>  32592.496055</td>\n",
       "      <td> 0.941026</td>\n",
       "      <td> 0.071738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 328554.267926</td>\n",
       "      <td> 210422.837024</td>\n",
       "      <td>-0.695449</td>\n",
       "      <td> 1.630362</td>\n",
       "      <td> 328554.336546</td>\n",
       "      <td> 210425.172535</td>\n",
       "      <td>-0.695450</td>\n",
       "      <td> 1.630381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 328554.336546</td>\n",
       "      <td> 210425.172535</td>\n",
       "      <td>-0.695450</td>\n",
       "      <td> 1.630381</td>\n",
       "      <td>  81132.283847</td>\n",
       "      <td>  41709.762092</td>\n",
       "      <td> 0.896615</td>\n",
       "      <td> 0.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 344968.738188</td>\n",
       "      <td> 216345.805843</td>\n",
       "      <td>-0.869089</td>\n",
       "      <td> 0.700267</td>\n",
       "      <td>  60361.482975</td>\n",
       "      <td>  32784.424794</td>\n",
       "      <td> 0.942774</td>\n",
       "      <td> 0.075710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td> 168372.915918</td>\n",
       "      <td>  94781.016099</td>\n",
       "      <td> 0.554739</td>\n",
       "      <td> 0.260522</td>\n",
       "      <td>  73332.249794</td>\n",
       "      <td>  39238.895373</td>\n",
       "      <td> 0.915538</td>\n",
       "      <td> 0.087992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td> 152708.820848</td>\n",
       "      <td>  95112.321579</td>\n",
       "      <td> 0.633732</td>\n",
       "      <td> 0.269304</td>\n",
       "      <td>  61565.101471</td>\n",
       "      <td>  33998.133886</td>\n",
       "      <td> 0.940469</td>\n",
       "      <td> 0.077937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td> 237908.896727</td>\n",
       "      <td> 140873.910528</td>\n",
       "      <td> 0.111020</td>\n",
       "      <td> 0.492137</td>\n",
       "      <td>  70473.821657</td>\n",
       "      <td>  38098.250148</td>\n",
       "      <td> 0.921994</td>\n",
       "      <td> 0.093023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td> 328554.241267</td>\n",
       "      <td> 210416.451805</td>\n",
       "      <td>-0.695449</td>\n",
       "      <td> 1.630313</td>\n",
       "      <td> 328554.336546</td>\n",
       "      <td> 210425.172535</td>\n",
       "      <td>-0.695450</td>\n",
       "      <td> 1.630381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td> 328553.862599</td>\n",
       "      <td> 210417.448328</td>\n",
       "      <td>-0.695445</td>\n",
       "      <td> 1.630313</td>\n",
       "      <td>  78577.379462</td>\n",
       "      <td>  43430.411745</td>\n",
       "      <td> 0.903024</td>\n",
       "      <td> 0.100302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RMSE_NN         MAE_NN     R2_NN   MAPE_NN        RMSE_GN  \\\n",
       "2   328552.299152  210383.974363 -0.695429  1.630024   70656.170502   \n",
       "3   124019.990982   79489.201237  0.758424  0.225141   71304.611556   \n",
       "4   104314.704910   65649.546090  0.829092  0.174545   51738.555057   \n",
       "5   217303.288100  148541.217068  0.258343  0.477888  328554.336546   \n",
       "6   297306.045762  175616.015200 -0.388283  0.984764   60548.612695   \n",
       "7   123904.541936   76604.986607  0.758873  0.201801   65850.114461   \n",
       "8   192499.365168  136252.717521  0.417992  0.454460   59535.709836   \n",
       "9   201280.991082  133064.109023  0.363679  0.423395   69010.809400   \n",
       "10  175159.795779  112001.538198  0.518119  0.336259   57834.961503   \n",
       "11  285179.942668  175536.882830 -0.277346  0.884263   73754.053112   \n",
       "12  317660.520365  188048.841656 -0.584883  1.380264   61276.784169   \n",
       "13  328554.267926  210422.837024 -0.695449  1.630362  328554.336546   \n",
       "14  328554.336546  210425.172535 -0.695450  1.630381   81132.283847   \n",
       "15  344968.738188  216345.805843 -0.869089  0.700267   60361.482975   \n",
       "16  168372.915918   94781.016099  0.554739  0.260522   73332.249794   \n",
       "17  152708.820848   95112.321579  0.633732  0.269304   61565.101471   \n",
       "18  237908.896727  140873.910528  0.111020  0.492137   70473.821657   \n",
       "19  328554.241267  210416.451805 -0.695449  1.630313  328554.336546   \n",
       "20  328553.862599  210417.448328 -0.695445  1.630313   78577.379462   \n",
       "\n",
       "           MAE_GN     R2_GN   MAPE_GN  \n",
       "2    33742.822162  0.921590  0.071340  \n",
       "3    36076.375865  0.920144  0.077698  \n",
       "4    26915.557516  0.957956  0.061221  \n",
       "5   210425.172535 -0.695450  1.630381  \n",
       "6    31186.695624  0.942419  0.066647  \n",
       "7    32412.832290  0.931894  0.067321  \n",
       "8    29425.746252  0.944329  0.063149  \n",
       "9    36011.018284  0.925199  0.073061  \n",
       "10   30172.344352  0.947465  0.067356  \n",
       "11   38309.676224  0.914564  0.084385  \n",
       "12   32592.496055  0.941026  0.071738  \n",
       "13  210425.172535 -0.695450  1.630381  \n",
       "14   41709.762092  0.896615  0.104400  \n",
       "15   32784.424794  0.942774  0.075710  \n",
       "16   39238.895373  0.915538  0.087992  \n",
       "17   33998.133886  0.940469  0.077937  \n",
       "18   38098.250148  0.921994  0.093023  \n",
       "19  210425.172535 -0.695450  1.630381  \n",
       "20   43430.411745  0.903024  0.100302  \n",
       "\n",
       "[19 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_nresult= pd.DataFrame(list_nresult,columns=[\"RMSE_NN\",\"MAE_NN\",\"R2_NN\",\"MAPE_NN\",\"RMSE_GN\",\"MAE_GN\",\"R2_GN\",\"MAPE_GN\"],index=np.arange(2,21))\n",
    "list_nresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "list_nresult[\"MAPE_GN\"].plot(kind=\"line\")\n",
    "list_nresult[\"MAPE_NN\"].plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_score = pd.DataFrame(list_nresult,columns=[\"RMSE_GNP\",\"MAE_GNP\",\"R2_GNP\"],index=np.arange(4,16))\n",
    "result_score\n",
    "# temp = result_score[\"MAE_GN\"][13]\n",
    "# result_score[\"MAE_GN\"][13]=result_score[\"MAE_GN\"][11]\n",
    "# result_score[\"MAE_GN\"][11]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f49ed2eb610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "ax1 = list_nresult[\"MAPE_GN\"].plot(kind='line',label='MAPE GNP',color='red',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax2 = list_nresult[\"MAPE_NN\"].plot(kind='line',label='MAPE GN', color='blue',title=\"MAE vs. Window Size (Genetic Neural Network with Periodic)\",grid=False)\n",
    "ax1.set_xlabel(\"Sliding Window size\")\n",
    "ax1.set_ylabel(\"Mean Absolute Error (MAE)\")\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = HDFStore(\"experiement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store[\"mape_gnp\"] = list_nresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez(\"experiement_12-1\",gn_pred=gn_pred,nn_pred = nn_pred,mape_gnp=list_nresult,y_actual=y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
