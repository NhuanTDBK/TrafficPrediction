{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_solution(k,n):\n",
    "    archive = np.random.uniform(-1,1,size=(k*n)).reshape(k,n)\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(nn_model,archive,summary_writter=None):\n",
    "    fitness_solution = np.zeros(archive.shape[0])\n",
    "    for (index,candidate) in enumerate(archive):\n",
    "        result = nn_model.compute_error(candidate)\n",
    "#         print result\n",
    "        fitness_solution[index] = result\n",
    "    sorted_idx = np.argsort(fitness_solution)\n",
    "    sorted_archive = np.zeros(archive.shape)\n",
    "    for (index,item) in enumerate(sorted_idx):\n",
    "        sorted_archive[item] = archive[index]\n",
    "    summary_writter.append(fitness_solution.min())\n",
    "    return sorted_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(q,shape):\n",
    "    weights = np.zeros([shape[0],1])\n",
    "    # qk = 0.1\n",
    "    co_efficient = 1 / (0.1 * np.sqrt(2*np.pi))\n",
    "    for index in np.arange(shape[0]):\n",
    "        exponent = np.square(index-1) / (2*np.square(q*shape[0]))\n",
    "        weights[index] = co_efficient * np.exp(-exponent)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_deviation(i,l,archive,epsilon):\n",
    "    __doc__ = \" compute standard deviation with i, l, archive and epsilon\"\n",
    "    #Constant sd\n",
    "    sd = 0.01\n",
    "    co_efficient = epsilon / (archive.shape[0])\n",
    "    sum_sd = np.multiply(np.sum(archive[l]-archive[l][i]),epsilon)\n",
    "    if(sum_sd <= 0):\n",
    "        sum_sd = sd\n",
    "    return sum_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_pdf(archive_shape,weights):\n",
    "    sum_weights = np.sum(weights)\n",
    "    temp = 0\n",
    "    l = 0\n",
    "    pro_r = np.random.uniform(0.0,1.0)\n",
    "    for (index,weight) in enumerate(weights):\n",
    "        temp = temp + weight/sum_weights\n",
    "        if(temp > pro_r):\n",
    "            l = index\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_more(archive,weights,epsilon):\n",
    "    try:\n",
    "        sigma = 0.0\n",
    "        mu = 0.0\n",
    "        pdf = 0\n",
    "        next_archive = np.zeros(archive.shape)\n",
    "        for index in np.arange(archive.shape[0]):\n",
    "            i_pdf = choose_pdf(archive.shape,weights)\n",
    "            for item in np.arange(archive.shape[1]):\n",
    "                sigma = compute_standard_deviation(item,i_pdf,archive,epsilon)\n",
    "                mu = archive[pdf][item]\n",
    "    #             print sigma,mu\n",
    "                next_archive[index][item] = np.random.normal(mu,sigma)\n",
    "    except Exception as e:\n",
    "        print \"Sampling more\"\n",
    "        print e\n",
    "    return next_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,hidden_node):\n",
    "        print \"Initilization\"\n",
    "        self.hidden_node = hidden_node\n",
    "    def fit(self,X_training,y_training):\n",
    "        self.X_training = X_training\n",
    "        self.y_training = y_training\n",
    "    def activation(self,X,weights):\n",
    "#         N = weights.shape[0]\n",
    "#         weights_reshape = weights.reshape(N,1)\n",
    "#         print weights.shape\n",
    "#         print X.shape\n",
    "        return self.sigmoid(np.dot(X,weights))\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def compute_error(self,weights):\n",
    "        predict = self.activation(self.X_training,weights)\n",
    "        return np.sqrt(mean_squared_error(predict,self.y_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AntGradient(k,n,nn_model,summary_writter=None):\n",
    "    #Initialize parameter for CACO\n",
    "    number_of_layers = 3\n",
    "    number_of_weights = n\n",
    "    epsilon = 0.85\n",
    "    nn_shape = [4,1]\n",
    "    q = 0.08 \n",
    "    max_iteration = 100\n",
    "    error_criteria = 0.09\n",
    "    const_sd = 0.1\n",
    "    \n",
    "    count_dup = 3\n",
    "    best_error = np.inf\n",
    "    archive = init_solution(k,n)\n",
    "    stop_condition = False\n",
    "    duplicate = 0\n",
    "    best_error = np.Inf\n",
    "    for i in np.arange(max_iteration):\n",
    "        try:\n",
    "            sorted_archive = calculate_fitness(nn_model,archive,summary_writter)\n",
    "#             if(is_accepted(fitness_solution[0])):\n",
    "# #                 break\n",
    "            if((summary_writter[-1]-best_error)<=1E-7):\n",
    "                duplicate+=1\n",
    "                if(duplicate==count_dup):\n",
    "                    break\n",
    "                    print summary_writter[-1]\n",
    "            else:\n",
    "                best_error = summary_writter[-1]\n",
    "            weights = calculate_weights(q,archive.shape)\n",
    "            archive = sampling_more(sorted_archive,weights,epsilon)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print e,i\n",
    "            break\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = np.load(\"data.npz\")\n",
    "X_training = file_data[\"X_train\"]\n",
    "y_training = file_data[\"y_train\"].reshape(file_data[\"y_train\"].shape[0],1).astype(\"float32\")\n",
    "X_test = file_data[\"X_test\"]\n",
    "y_test = file_data[\"y_test\"].reshape(file_data[\"y_test\"].shape[0],1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilization\n"
     ]
    }
   ],
   "source": [
    "nn_model = NeuralNetwork(15)\n",
    "nn_model.fit(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3673113571530936, 0.32669583118349133, 0.28737316365006005]"
      ]
     },
     "execution_count": 236,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "summary_writer = []\n",
    "weights = AntGradient(100,4,nn_model,summary_writer)\n",
    "summary_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}