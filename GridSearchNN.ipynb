{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano\n",
    "import lasagne as ls\n",
    "from theano import tensor as T\n",
    "from lasagne.layers import InputLayer, DenseLayer\n",
    "from lasagne.updates import nesterov_momentum,sgd\n",
    "from lasagne.nonlinearities import rectify\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit\n",
    "\n",
    "# class NNGridSearch:\n",
    "#     def __init__(self,X_training,y_training,n_sample2,n_test2):\n",
    "#         if(X_training.shape[0]!=y_training.shape[0]):\n",
    "#             print \"X_training shape must match y_training shape\"\n",
    "#         self.X_training = X_training\n",
    "#         self.y_training = y_training\n",
    "#         self.n_sample2 = n_sample2\n",
    "#         self.n_test2 = n_test2\n",
    "#         print \"Generate X_test and y_test\"\n",
    "#         n_input = 11\n",
    "#         print \"X_test...\"\n",
    "#         print \"Multi Layer Perceptron...\"\n",
    "#         #Build layer for MLP\n",
    "#         self.l_in = ls.layers.InputLayer(shape=(None,10),input_var=None)\n",
    "#         self.l_hidden = ls.layers.DenseLayer(self.l_in,num_units=15,nonlinearity=ls.nonlinearities.sigmoid)\n",
    "#         self.network = l_out = ls.layers.DenseLayer(self.l_hidden,num_units=1)\n",
    "#         print \"Neural network initialize\"\n",
    "#     def gridsearch_alpha(self,learning_rate):\n",
    "#         self.result = np.zeros(len(learning_rate),dtype=np.float64)\n",
    "#         i=0\n",
    "#         for item in learning_rate:\n",
    "#             #Init Neural net\n",
    "#             net1 = NeuralNet(\n",
    "#                 layers=self.network,\n",
    "#                 # optimization method:\n",
    "#                 update=nesterov_momentum,\n",
    "#                 update_learning_rate=item,\n",
    "#                 update_momentum=0.9,\n",
    "#                 regression=True,  # flag to indicate we're dealing with regression problem\n",
    "#                 max_epochs=400,  # we want to train this many epochs\n",
    "# #                 verbose=1,\n",
    "#                 train_split = TrainSplit(10)\n",
    "#             )\n",
    "#             #\n",
    "#             print \"Training time!!!!!.....\"\n",
    "#             net1.fit(self.X_training,self.y_training)\n",
    "#             self.pred = net1.predict(self.n_sample2)\n",
    "#             net1.save_params_to(\"saveNeuralNetwork .tdn\")\n",
    "#             score_nn = net1.score(self.n_sample2,self.n_test2)\n",
    "#             print \"Score rate = \"\n",
    "#             print score_nn\n",
    "#             self.result[i+1]=score_nn\n",
    "#         print result.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from __init__ import *\n",
    "# X_training, y_training,n_sample2,n_test2 = get_training()\n",
    "# learning_rate = [0.1,0.001,0.0001,0.00001,0.000001]\n",
    "# result = np.zeros(len(learning_rate),dtype=np.float64)\n",
    "# test = NNGridSearch(X_training,y_training,n_sample2,n_test2)\n",
    "# test.gridsearch_alpha(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ninput = np.arange(2,21)\n",
    "learning_rate = [0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
    "# list_results = np.zeros([ list_ninput.shape[0], learning_rate.shape[0] ])\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: storeResult.h5\n",
       "/results            frame        (shape->[19,6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import HDFStore\n",
    "storeR = HDFStore(\"storeResult.h5\")\n",
    "storeR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = storeR[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>1e-05</th>\n",
       "      <th>1e-06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td> 0.202628</td>\n",
       "      <td> 0.202628</td>\n",
       "      <td> 0.202628</td>\n",
       "      <td> 0.202628</td>\n",
       "      <td> 0.202628</td>\n",
       "      <td> 0.202628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td> 0.009875</td>\n",
       "      <td> 0.009875</td>\n",
       "      <td> 0.009875</td>\n",
       "      <td> 0.009875</td>\n",
       "      <td> 0.009875</td>\n",
       "      <td> 0.009875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td> 0.010269</td>\n",
       "      <td> 0.010269</td>\n",
       "      <td> 0.010269</td>\n",
       "      <td> 0.010269</td>\n",
       "      <td> 0.010269</td>\n",
       "      <td> 0.010269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td> 0.010060</td>\n",
       "      <td> 0.010060</td>\n",
       "      <td> 0.010060</td>\n",
       "      <td> 0.010060</td>\n",
       "      <td> 0.010060</td>\n",
       "      <td> 0.010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> 0.010925</td>\n",
       "      <td> 0.010925</td>\n",
       "      <td> 0.010925</td>\n",
       "      <td> 0.010925</td>\n",
       "      <td> 0.010925</td>\n",
       "      <td> 0.010925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td> 0.207509</td>\n",
       "      <td> 0.207509</td>\n",
       "      <td> 0.207509</td>\n",
       "      <td> 0.207509</td>\n",
       "      <td> 0.207509</td>\n",
       "      <td> 0.207509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td> 0.010895</td>\n",
       "      <td> 0.010895</td>\n",
       "      <td> 0.010895</td>\n",
       "      <td> 0.010895</td>\n",
       "      <td> 0.010895</td>\n",
       "      <td> 0.010895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td> 0.205645</td>\n",
       "      <td> 0.205645</td>\n",
       "      <td> 0.205645</td>\n",
       "      <td> 0.205645</td>\n",
       "      <td> 0.205645</td>\n",
       "      <td> 0.205645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td> 0.204781</td>\n",
       "      <td> 0.204781</td>\n",
       "      <td> 0.204781</td>\n",
       "      <td> 0.204781</td>\n",
       "      <td> 0.204781</td>\n",
       "      <td> 0.204781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td> 0.203686</td>\n",
       "      <td> 0.203686</td>\n",
       "      <td> 0.203686</td>\n",
       "      <td> 0.203686</td>\n",
       "      <td> 0.203686</td>\n",
       "      <td> 0.203686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td> 0.011006</td>\n",
       "      <td> 0.011006</td>\n",
       "      <td> 0.011006</td>\n",
       "      <td> 0.011006</td>\n",
       "      <td> 0.011006</td>\n",
       "      <td> 0.011006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td> 0.202363</td>\n",
       "      <td> 0.202363</td>\n",
       "      <td> 0.202363</td>\n",
       "      <td> 0.202363</td>\n",
       "      <td> 0.202363</td>\n",
       "      <td> 0.202363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td> 0.201347</td>\n",
       "      <td> 0.201347</td>\n",
       "      <td> 0.201347</td>\n",
       "      <td> 0.201347</td>\n",
       "      <td> 0.201347</td>\n",
       "      <td> 0.201347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 0.010914</td>\n",
       "      <td> 0.010914</td>\n",
       "      <td> 0.010914</td>\n",
       "      <td> 0.010914</td>\n",
       "      <td> 0.010914</td>\n",
       "      <td> 0.010914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td> 0.201796</td>\n",
       "      <td> 0.201796</td>\n",
       "      <td> 0.201796</td>\n",
       "      <td> 0.201796</td>\n",
       "      <td> 0.201796</td>\n",
       "      <td> 0.201796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td> 0.201350</td>\n",
       "      <td> 0.201350</td>\n",
       "      <td> 0.201350</td>\n",
       "      <td> 0.201350</td>\n",
       "      <td> 0.201350</td>\n",
       "      <td> 0.201350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td> 0.012003</td>\n",
       "      <td> 0.012003</td>\n",
       "      <td> 0.012003</td>\n",
       "      <td> 0.012003</td>\n",
       "      <td> 0.012003</td>\n",
       "      <td> 0.012003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td> 0.201029</td>\n",
       "      <td> 0.201029</td>\n",
       "      <td> 0.201029</td>\n",
       "      <td> 0.201029</td>\n",
       "      <td> 0.201029</td>\n",
       "      <td> 0.201029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td> 0.012524</td>\n",
       "      <td> 0.012524</td>\n",
       "      <td> 0.012524</td>\n",
       "      <td> 0.012524</td>\n",
       "      <td> 0.012524</td>\n",
       "      <td> 0.012524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.100000  0.010000  0.001000  0.000100  0.000010  0.000001\n",
       "2   0.202628  0.202628  0.202628  0.202628  0.202628  0.202628\n",
       "3   0.009875  0.009875  0.009875  0.009875  0.009875  0.009875\n",
       "4   0.010269  0.010269  0.010269  0.010269  0.010269  0.010269\n",
       "5   0.010060  0.010060  0.010060  0.010060  0.010060  0.010060\n",
       "6   0.010925  0.010925  0.010925  0.010925  0.010925  0.010925\n",
       "7   0.207509  0.207509  0.207509  0.207509  0.207509  0.207509\n",
       "8   0.010895  0.010895  0.010895  0.010895  0.010895  0.010895\n",
       "9   0.205645  0.205645  0.205645  0.205645  0.205645  0.205645\n",
       "10  0.204781  0.204781  0.204781  0.204781  0.204781  0.204781\n",
       "11  0.203686  0.203686  0.203686  0.203686  0.203686  0.203686\n",
       "12  0.011006  0.011006  0.011006  0.011006  0.011006  0.011006\n",
       "13  0.202363  0.202363  0.202363  0.202363  0.202363  0.202363\n",
       "14  0.201347  0.201347  0.201347  0.201347  0.201347  0.201347\n",
       "15  0.010914  0.010914  0.010914  0.010914  0.010914  0.010914\n",
       "16  0.201796  0.201796  0.201796  0.201796  0.201796  0.201796\n",
       "17  0.201350  0.201350  0.201350  0.201350  0.201350  0.201350\n",
       "18  0.012003  0.012003  0.012003  0.012003  0.012003  0.012003\n",
       "19  0.201029  0.201029  0.201029  0.201029  0.201029  0.201029\n",
       "20  0.012524  0.012524  0.012524  0.012524  0.012524  0.012524\n",
       "\n",
       "[19 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ax = pl.subplot()\n",
    "# ax.set_color_cycle(['blue','red'])\n",
    "# ax.plot(n_test2,label=\"actual\")\n",
    "# ax.plot(test.pred,label=\"predict\")\n",
    "# ax.legend()\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
